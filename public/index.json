[{"categories":["heartbeat"],"content":"阳光明媚，温暖人心的小太阳。","date":"2024-01-20","objectID":"https://www.bardblog.cn/my-love/","tags":["gentle","sunlight"],"title":"我的小太阳","uri":"https://www.bardblog.cn/my-love/"},{"categories":["heartbeat"],"content":"新年第一篇博客，总结过去，展望未来。 ","date":"2024-01-20","objectID":"https://www.bardblog.cn/my-love/:0:0","tags":["gentle","sunlight"],"title":"我的小太阳","uri":"https://www.bardblog.cn/my-love/"},{"categories":["heartbeat"],"content":"总结2023 2023总体是非常emo的，经历了很多的事情，度过了一段痛苦的岁月，人也成长了一些。往事如烟，人需要忘记过去，把握现在，和过去告别，感恩所有帮助我的朋友。 ","date":"2024-01-20","objectID":"https://www.bardblog.cn/my-love/:1:0","tags":["gentle","sunlight"],"title":"我的小太阳","uri":"https://www.bardblog.cn/my-love/"},{"categories":["heartbeat"],"content":"新的2024 我感觉我的运气似乎变好了很多,今年认识了一个很有趣很好很善良真诚的人。相似的家庭和成长经历，相似的性格，一样的血型…我们无话不说，聊自己小时候，聊自己的家庭，过去的情感经历…这给我一种很奇妙的感觉，我感觉自己很快乐，有时候又会很失落，会时不时打开微信看看有没有来自她的消息，每次点开聊天窗口真的好激动，我有时候也会在想我也是谈过恋爱的，二十好几都快三十的人，怎么还像一个情窦初开的少年那样。真的很想快点见到她，但是又害怕会让对方失望，复杂情绪交织着，激动期待又忐忑吧。前天晚上我们聊了好久好久，我第一次可以和一个人可以聊天聊的通宵，最后我们都实在困的受不了了…这种感觉真的很奇妙，我感觉我的内心深处有有一根弦被撩拨着，像是在无形中编织了一张网。第二天两人都困的不行，我请了个假，她继续去公司搬砖、化妆、公司年会…累了一天，想想突然觉得自己有点自私，只顾着聊天开心，忘了她在生理期而且第二天还有很重要的事，想想很内疚，以后不能再这样了。 我有时候觉得我应该更勇敢一点，但是又害怕没有把握好这个度，因为炽热的心可以温暖一个人，但也有可能灼伤对方。但是人很多时候不会因为自己做了什么而后悔，而是因为没有做什么；人总要在自己年轻的时候做点什么，享受这个过程，结局似乎不是那么重要。 真的好希望她是永远的小太阳，永远幸福开心快乐，在她暗淡的时候我能照亮的她，温暖她，两个人一起对抗黑暗，对抗人生的的苦难。 我应该成为一个很好的人，因为只有自己是个很好的人才能去保护、爱护、对一个人好。我发觉自己有好多的缺点，但是我愿意去改变，但是不能停在口头上而已，我能想到的目前可以做的就是减肥，确实是有点胖了，自己看着都有点讨厌了… When you are no longer young and beautiful,I will still love you,I know i will.没有人可以永远年轻，我们都会随着年龄的增长身体 变得衰老，亦不复年轻时的容颜，但是炽热的心不会因为时间而变得冷淡，而是随着岁月的沉淀愈发变得温暖而坚定。就像父母爱情里面的那样，江德福和安杰一起度过漫长岁月，两人的感情随着岁月愈发醇厚，如同一坛老酒不会因为时间而变质过期，反而变得更有味道了。其实爱很简单，就像歌词里面唱的那样“用最真诚的心，让爱变得简单”。 以自己为原点扩展的社会关系中，优先级应该依次是伴侣、孩子、父母，兄弟姐妹、朋友。人总要先爱自己才能爱别人，一个好男人不在于他学历有多高、赚钱能力有多强，长得有多帅…这些固然都是加分项，但不是真正的内核，真正的内核应该是在真正碰到事的时候的体现的作出选择、应对困难、以及解决问题的能力。岁月静好风平浪静处于一个轻松愉悦并且熟悉的环境中，大多数人都能作出较好的反应；但真正碰到事的时候才能看清楚一个人，因为只有这种情况下才是一个人最真挚的反应。父母爱情中江德福能够为了安杰放弃自己的前途回乡下种田，安杰也可以为了爱情放弃从小优渥的生活永远跟着江德福，他们经受住了考验。这件事其实就已经为他们一辈子的幸福婚姻做下了注解。努力让自己成为一个更好的人，爱自己、爱自己爱的人以及爱自己的人。 ","date":"2024-01-20","objectID":"https://www.bardblog.cn/my-love/:2:0","tags":["gentle","sunlight"],"title":"我的小太阳","uri":"https://www.bardblog.cn/my-love/"},{"categories":["technology"],"content":"深度优先搜索解决连通块问题","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"题目描述 给定一颗树，树中包含 n 个结点（编号 1∼n）和 n−1 条无向边。 请你找到树的重心，并输出将重心删除后，剩余各个连通块中点数的最大值。 重心定义：重心是指树中的一个结点，如果将这个点删除后，剩余各个连通块中点数的最大值最小，那么这个节点被称为树的重心。 输入格式 第一行包含整数 n，表示树的结点数。 接下来 n−1 行，每行包含两个整数 a 和 b，表示点 a 和点 b 之间存在一条边。 输出格式 输出一个整数 m，表示将重心删除后，剩余各个连通块中点数的最大值。 数据范围 1≤n≤105 输入样例: 9 1 2 1 7 1 4 2 8 2 5 4 3 3 9 4 6 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/:1:0","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"实现思路 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/:2:0","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"代码实现 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/:3:0","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"代码1 package main import ( \"bufio\" \"fmt\" \"os\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) son := make(map[int]*listNode) used := make([]bool, n+1) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 2000*1000) scanner.Buffer(buf, len(buf)) for i := 0; i \u003c n-1; i++ { scanner.Scan() ss := strings.Split(scanner.Text(), \" \") var a, b int a, _ = strconv.Atoi(ss[0]) b, _ = strconv.Atoi(ss[1]) add1(son, used, a, b) } res := n dfs1(son, n, 1, \u0026res, make([]bool, n+1)) fmt.Println(res) } func dfs1(mp map[int]*listNode, n, t int, res *int, visited []bool) int { visited[t] = true tmp := 0 sum := 1 for h := mp[t]; h != nil; h = h.next { if !visited[h.val] { s := dfs1(mp, n, h.val, res, visited) tmp = max(tmp, s) sum += s } } tmp = max(tmp, n-sum) *res = min(*res, tmp) return sum } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } // add 构造图 // son，存储编号为k的节点的孩子节点 // used 编号为b的节点是否曾经是某个节点的孩子节点,是否被用作过孩子节点 // 因为同一个节点只能是一个节点的孩子节点，所以如果b节点之前为某个节点的孩子节点，那么此时b节点是a节点的父节点，a节点是b节点的孩子节点 func add1(son map[int]*listNode, used []bool, a, b int) { if !used[b] { newNode := \u0026listNode{val: b, next: son[a]} son[a] = newNode used[b] = true } else { newNode := \u0026listNode{val: a, next: son[b]} son[b] = newNode } } type listNode struct { val int next *listNode } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/:3:1","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"代码2 package main import ( \"bufio\" \"fmt\" \"os\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) h, c, ne := make([]int, n+1), make([]int, 2*n+1), make([]int, 2*n+1) for i := 0; i \u003c= n; i++ { h[i] = -1 } idx := 0 visited := make([]bool, n+1) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 20000*1000) scanner.Buffer(buf, len(buf)) for i := 0; i \u003c n-1; i++ { scanner.Scan() s := scanner.Text() ss := strings.Split(s, \" \") var a, b int a, _ = strconv.Atoi(ss[0]) b, _ = strconv.Atoi(ss[1]) add2(h, c, ne, a, b, \u0026idx) add2(h, c, ne, b, a, \u0026idx) } res := n dfs2(h, c, ne, n, 1, visited, \u0026res) fmt.Println(res) } func dfs2(h, c, ne []int, n, t int, visited []bool, res *int) int { visited[t] = true sum := 1 tmp := 0 for i := h[t]; i != -1; i = ne[i] { if !visited[c[i]] { s := dfs2(h, c, ne, n, c[i], visited, res) sum += s tmp = max(tmp, s) } } tmp = max(tmp, n-sum) *res = min(*res, tmp) return sum } // 建立连接图 // 参考https://www.acwing.com/file_system/file/content/whole/index/content/4446359/ func add2(h, c, ne []int, p, s int, idx *int) { c[*idx] = s ne[*idx] = h[p] h[p] = *idx *idx += 1 } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-dfs-acwing-846/:3:2","tags":["algorithm","bfs"],"title":"连通块点数最大值","uri":"https://www.bardblog.cn/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"bfs解决最短路问题","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-bfs-acwing-844/","tags":["algorithm","bfs"],"title":"迷宫最小的移动次数","uri":"https://www.bardblog.cn/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"题目描述 给定一个 n×m 的二维整数数组，用来表示一个迷宫，数组中只包含 0 或 1，其中 0 表示可以走的路，1 表示不可通过的墙壁。 最初，有一个人位于左上角 (1,1) 处，已知该人每次可以向上、下、左、右任意一个方向移动一个位置。 请问，该人从左上角移动至右下角 (n,m) 处，至少需要移动多少次。 数据保证 (1,1) 处和 (n,m) 处的数字为 0，且一定至少存在一条通路。 输入格式 第一行包含两个整数 n 和 m。 接下来 n 行，每行包含 m 个整数（0 或 1），表示完整的二维数组迷宫。 输出格式 输出一个整数，表示从左上角移动至右下角的最少移动次数。 数据范围 1≤n,m≤100 输入样例： 5 5 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 输出样例： 8 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-bfs-acwing-844/:1:0","tags":["algorithm","bfs"],"title":"迷宫最小的移动次数","uri":"https://www.bardblog.cn/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"实现思路 典型的最短路问题，遍历从起始到终点的路径，记录最小值。 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-bfs-acwing-844/:2:0","tags":["algorithm","bfs"],"title":"迷宫最小的移动次数","uri":"https://www.bardblog.cn/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"代码实现 package main import \"fmt\" const N = 101 func main() { var n, m int fmt.Scanf(\"%d%d\", \u0026n, \u0026m) nums := make([][]int, n) d := make([][]int, n) for i := 0; i \u003c n; i++ { nums[i] = make([]int, m) d[i] = make([]int, m) for j := 0; j \u003c m; j++ { var tmp int fmt.Scanf(\"%d\", \u0026tmp) nums[i][j] = tmp d[i][j] = -1 } } fmt.Println(bfs(nums, d, newQueue(N*N))) } func bfs(nums, d [][]int, q *queue) int { n, m := len(nums), len(nums[0]) d[0][0] = 0 dx := [4]int{-1, 0, 1, 0} dy := [4]int{0, 1, 0, -1} q.push(\u0026pair{0, 0}) for !q.isEmpty() { t := q.pop() for i := 0; i \u003c 4; i++ { // 上下左右四个方向寻找 x, y := t.x+dx[i], t.y+dy[i] // 当前位置的下一个位置 if x \u003e= 0 \u0026\u0026 x \u003c n \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c m \u0026\u0026 nums[x][y] == 0 \u0026\u0026 d[x][y] == -1 { d[x][y] = d[t.x][t.y] + 1 q.push(\u0026pair{x, y}) } } } return d[n-1][m-1] } type pair struct { x int y int } type queue struct { elements []*pair begin int end int } func newQueue(n int) *queue { return \u0026queue{ elements: make([]*pair, n), begin: 0, end: -1, } } func (q *queue) push(p *pair) { q.end += 1 q.elements[q.end] = p } func (q *queue) pop() *pair { res := q.elements[q.begin] q.elements[q.begin] = nil q.begin += 1 return res } func (q *queue) isEmpty() bool { return q.end \u003c q.begin } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-bfs-acwing-844/:3:0","tags":["algorithm","bfs"],"title":"迷宫最小的移动次数","uri":"https://www.bardblog.cn/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"三种工厂模式","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"工厂模式大致可分为 简单工厂模式 工厂方法模式 抽象工厂模式 下面就这三种工厂模式做一下介绍并配上实现代码 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/:0:0","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"简单工厂模式 简单工厂模式，也叫静态方法模式，在对象创建工厂类中定义了一个静态方法来创建对象，简单工厂设计模式让客户端（使用者）无需知道对象的具体细节就能创建出所需的产品实例，使用者可以直接使用生产出来的对象而无需关心对象是如何生产出来的。 类图： 简单工厂模式 代码： package main import \"fmt\" type Animal interface { eat() weight() int } type Dog struct { } func (d *Dog) eat() { fmt.Println(\"dog eat !\") } func (d *Dog) weight() int { return 30 } type Cat struct { } func (c *Cat) eat() { fmt.Println(\"cat eat!\") } func (c *Cat) weight() int { return 10 } type AnimalFactory struct { } func (a *AnimalFactory) newAnimal(animalType int) Animal { switch animalType { case 0: return \u0026Dog{} case 1: return \u0026Cat{} default: return nil } } func main() { factory := new(AnimalFactory) dog := factory.newAnimal(0) dog.eat() fmt.Println(dog.weight()) cat := factory.newAnimal(1) cat.eat() fmt.Println(cat.weight()) } 可以看到简单工厂模式还是挺简单的，实现了将创建实例和使用实例分离，使用者无需关心实例创建过程，实现了分离解耦，无需知道被创建对象的详细信息，只需要知道该对象对应的类型映射即可。那么简单工厂模式有什么缺点呢？在生产对象的时候，根据传入的animal类型来确定创建哪个具体的动物对象，当我们增加更多的annimal种类的时候，比如增加兔子、大象等animal，随着动物种类的越来越多，newAnimal方法就会不断膨胀，并且每次动物种类发生变动的时候，都要去修改这部分代码，不符合开闭原则。 那么如何解决上述问题呢？其实也不能说解决，只能算一个编程小技巧，可以发现newAnimal方法大量的swich case，每次如何干掉这些swich case呢？在main函数中，当我们需要创建某个具体动物对象的时候，需要传入animalType字段然后调用newAnimal方法创建对象，也就是说，我们需要用到某个动物对象的时候才去创建，是一种“懒加载思想”;如果我们每次增加一个新的动物的时候，就创建该动物的实例，然后放到一个map字典中，在要用到该动物的时候，直接从map中取，不就不用维护一个newAnimal方法吗？其实就是把“懒加载思想”转化为“饿加载思想”，不管你用不用我这个对象，我这个对象既然存在，不管三七二十一，就创建一个对象实例塞到map字典里面再说。代码可以改为如下这样： 代码： package main import \"fmt\" // 饿加载，注册到map工厂 func init() { Register(0, \u0026Dog{}) Register(1, \u0026Cat{}) } type Animal interface { eat() weight() int } type Dog struct { } func (d *Dog) eat() { fmt.Println(\"dog eat !\") } func (d *Dog) weight() int { return 30 } type Cat struct { } func (c *Cat) eat() { fmt.Println(\"cat eat!\") } func (c *Cat) weight() int { return 10 } type AnimalFactory struct { } func Register(animalType int, animal Animal) { animals[animalType] = animal } func Get(animalType int) Animal { a, ok := animals[animalType] if !ok { return nil } return a } var animals = make(map[int]Animal) // animal type =\u003e Animal func main() { dog := Get(0) dog.eat() fmt.Println(dog.weight()) cat := Get(1) cat.eat() fmt.Println(cat.weight()) } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/:1:0","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"工厂方法模式 工厂方法模式也叫多态工厂模式，前面介绍了一下简单工厂模式，动物创建工厂无论什么Dog还是Cat都在同一个动物工厂生产，每次需要增加新的动物种类的时候，动物工厂都需要作出相应的改变。就好比，每次生产一个新的动物物种，都需要增加相应的配套工具，这对于系统的扩展性不是很好。工厂方法模式可以看作是对简单工厂模式的一种升级，即不同种类的动物不再在同一个动物工厂生产了，而是进行了细分，每种类型的动物都有一个专门的动物工厂进行生产，这里以汽车作为例子。 类图： 工厂方法模式 代码： package main import \"fmt\" // Car 汽车抽象接口，定义car的两个行为，开车和加油 type Car interface { drive() oil(cnt int) } // Bmw 宝马汽车 type Bmw struct { } func (b *Bmw) drive() { fmt.Println(\"i drive bmw!\") } func (b *Bmw) oil(cnt int) { fmt.Println(\"bmw add \", cnt, \" oil\") } // Benz 奔驰汽车 type Benz struct { } func (b *Benz) drive() { fmt.Println(\"i drive benz!\") } func (b *Benz) oil(cnt int) { fmt.Println(\"benz add \", cnt, \" oil\") } // CarFactory 汽车工厂接口，生产汽车 type CarFactory interface { makeCar() Car } // BmwFactory 宝马汽车工厂，生产宝马汽车 type BmwFactory struct { } func (b *BmwFactory) makeCar() Car { return new(Bmw) } // BenzFactory 奔驰汽车工厂，生产奔驰汽车 type BenzFactory struct { } func (b *BenzFactory) makeCar() Car { return new(Benz) } func main() { bmwFactory := new(BmwFactory) bmw := bmwFactory.makeCar() bmw.drive() bmw.oil(1) benzFactory := new(BenzFactory) benz := benzFactory.makeCar() benz.drive() benz.oil(2) } 简单总结一下工厂方法模式的优缺点： 优点： 1.可扩展性好，当需要增加一款新的产品时（如添加奥迪汽车），无需修改抽象工厂和抽象工厂提供的接口，祝需要添加一个具体工厂和具体产品就行了，更加符合“开闭原则”，简单工厂模式则需要修改工厂类的判断逻辑， 2.符合单一职责原则：每个具体工厂类只负责生产对应的产品。简单工厂模式的工厂类还需要有一定逻辑判断 3.基于⼯⼚⻆⾊和产品⻆⾊的多态性设计是⼯⼚⽅法模式的关键。它能够使⼯⼚可以⾃主确定创建何种产品对象（该产品的工厂类只需要实现抽象工厂接口即可），⽽如何创建这个对象的细节则完全封装在具体⼯⼚内部。⼯⼚⽅法模式之所以⼜被称为多态⼯⼚模式，是因为所有的具体⼯⼚类都具有同⼀抽象⽗类。 缺点： 1.每次添加新的产品，都需要编写新的具体产品类，并且同时也要提供该产品对应的工厂类，当系统中产品数量表多的时候，类的个数会因此成倍增加，会在一定成都上导致系统的复杂性，并且多个类需要编译运行，会在一定程度上增加系统的开销 2.一个具体工厂类只能创建一种具体产品 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/:2:0","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"抽象工厂模式 抽象工厂模式可以理解为生产工厂的工厂，即有一个超级工厂生产其他的工厂。马克思说过：“人是一切社会关系的总和”，一个人在社会上不可能只扮演一种角色，一个人的职业可能是程序员、也有其相应的家庭角色；同时程序员也有go、java、python程序员等，家庭角色也可能是是父亲、儿子、 丈夫等，共同构成了社会关系的总和。抽象工厂模式可以理解为简单工厂模式和工厂方法模式的结合体。自然也继承了各自的优缺点。 类图： 抽象工厂模式 代码： package main import \"fmt\" type programmer interface { writeCode() } type javaProgrammer struct { } func (j *javaProgrammer) writeCode() { fmt.Println(\"i am a java programmer,i write java\") } type goProgrammer struct { } func (g *goProgrammer) writeCode() { fmt.Println(\"i am a golang programmer,i write go\") } type family interface { love() } type father struct { } func (f *father) love() { fmt.Println(\"i am a father ,i love my wife and my son\") } type son struct { } func (s *son) love() { fmt.Println(\"i am a son ,i love my father and my mother\") } type programmerFactory struct { } func (p *programmerFactory) getProgrammer(programmerType int) programmer { switch programmerType { case 0: return new(javaProgrammer) case 1: return new(goProgrammer) default: return nil } } func (p *programmerFactory) getFamily(roleType int) family { return nil } type familyFactory struct { } func (f *familyFactory) getFamily(roleType int) family { switch roleType { case 0: return new(father) case 1: return new(son) default: return nil } } func (f *familyFactory) getProgrammer(programmerType int) programmer { return nil } type abstractHumanFactory interface { getFamily(roleType int) family getProgrammer(programmerType int) programmer } type factoryProducer struct { } func (*factoryProducer) getFactory(factoryType int) abstractHumanFactory { switch factoryType { case 0: return new(programmerFactory) case 1: return new(familyFactory) default: return nil } } func main() { fac := new(factoryProducer) programmerFac := fac.getFactory(0) java := programmerFac.getProgrammer(0) java.writeCode() golang := programmerFac.getProgrammer(1) golang.writeCode() familyFac := fac.getFactory(1) f := familyFac.getFamily(0) f.love() s := familyFac.getFamily(1) s.love() } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/:3:0","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"小结 工厂模式作为最简单也最容易理解同时也是日常使用比较多的一个设计模式，大致可分为三种，在日常开发过程中，正确的使用设计模式能够极大的简化我们的代码，降低代码的耦合度，提升可维护性（毕竟是前人经验的总结），但切记千万不能滥用设计模式，使用不当可能会适得其反，千万不要为了使用设计模式而去使用设计模式！！！ ","date":"2023-06-24","objectID":"https://www.bardblog.cn/desigin-pattern-factory/:4:0","tags":["design-pattern"],"title":"设计模式之工厂模式","uri":"https://www.bardblog.cn/desigin-pattern-factory/"},{"categories":["technology"],"content":"贪心算法解决区间合并问题","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-greedy-disjoint/","tags":["algorithm","greed"],"title":"最大不相交区间数量","uri":"https://www.bardblog.cn/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"题目描述 给定 N个闭区间 [ai,bi]，请你在数轴上选择若干个区间，使得选中的区间之间互不相交（包括端点）。 输出可选取区间的最大数量。 输入格式 第一行包含整数 N ，表示区间数。 接下来 N 行，每行包含两个整数 ai,bi ，表示一个区间的两个端点。 输出格式 输出一个整数，表示可选取区间的最大数量。 数据范围 1≤N≤105 , −109≤ai≤bi≤109 输入样例： 3 -1 1 2 4 3 5 输出样例： 2 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-greedy-disjoint/:1:0","tags":["algorithm","greed"],"title":"最大不相交区间数量","uri":"https://www.bardblog.cn/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"代码实现 package main import ( \"bufio\" \"fmt\" \"os\" \"sort\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 2000*1024) scanner.Buffer(buf, len(buf)) points := make([][]int, n) for i := 0; i \u003c n; i++ { scanner.Scan() strList := strings.Split(scanner.Text(), \" \") a, _ := strconv.Atoi(strList[0]) b, _ := strconv.Atoi(strList[1]) points[i] = []int{a, b} } sort.Slice(points, func(i, j int) bool { return points[i][1] \u003c points[j][1] }) cnt := 1 rightPoint := points[0][1] for i := 1; i \u003c n; i++ { if points[i][0] \u003e rightPoint { cnt++ rightPoint = points[i][1] } } fmt.Println(cnt) } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-greedy-disjoint/:2:0","tags":["algorithm","greed"],"title":"最大不相交区间数量","uri":"https://www.bardblog.cn/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"证明 先把原始区间按照右端点从小到大排序 对于第一个区间，选择右端点 从第二个区间开始，判断两个区间是否有交集，如果有交集，则合并两个区间（rightPoint是合并之前区间内最小右端点）；否则不相交区间+1 对于第k个区间，如果当前区间和前面所有区间（如果当前区间的左端点大于之前区间的最小右端点）都不相交， 不相交区间+1 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/algorithm-greedy-disjoint/:3:0","tags":["algorithm","greed"],"title":"最大不相交区间数量","uri":"https://www.bardblog.cn/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"详解golang 的gmp调度模型","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"进程线程协程 无论程序使用何种编程语言编写，它们最终都在操作系统中运行。运行中的程序被视为进程，每个进程拥有独立的内存空间和资源，且进程之间相互隔离。通常，应用程序具有多种功能，例如聊天应用在进行语音通话时还可以进行文字聊天。支撑这些功能运行的并非进程，而是线程。线程属于进程，一个进程可以拥有多个线程，它们并发执行以支持进程的多个功能。进程和线程作为操作系统的基本单位或资源，多线程技术充分利用现代CPU的多核资源，提高任务执行效率。 尽管进程-线程两级结构被广泛应用于软件开发，线程并非足够轻量。线程在完成任务的同时，还需承担额外开销，如线程切换。当线程因I/O或锁等原因阻塞时，会发生线程切换。然而，切换过程耗时较长，导致CPU资源得不到充分利用。因此，需要更轻量级的执行单元以提高切换效率，从而充分利用CPU资源。Go语言通过实现协程（goroutine）和调度机制，为开发者提供了更轻量级的执行单元。与线程相比，协程保存的上下文内容更少，切换速度更快，从而高效利用系统资源，提高并发度。 协程是用户级线程，由Go运行时（runtime）管理和调度，而非直接由操作系统管理。这使得Go运行时能在较少的操作系统线程上调度大量协程，降低线程切换开销。当协程因I/O或其他原因阻塞时，Go运行时将其他协程调度到同一操作系统线程上运行，实现高效并发执行。 Go语言的协程模型简化了高并发程序编写。使用关键字go，开发者轻松创建新协程并发执行函数。Go语言还提供强大的并发原语，如通道（channel）和同步原语（如互斥锁和WaitGroup），帮助开发者在协程间进行安全的数据传递和同步。 ","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:1:0","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"GMP调度机制 Go语言实现了一套高效的调度机制，在运行时管理和调度goroutine，而不是让操作系统直接管理。这种机制类似于“虚拟线程”的概念，Go在语言层面模拟了操作系统线程切换机制。 在传统的进程-线程二级结构中，一个线程隶属于某个固定的进程，一个进程可以拥有多个线程，形成1:M的模型。然而，在Go语言的GMP模型中，协程（G）和线程（M）之间形成了一个M:N的模型。这意味着一个协程并不是固定承载在一个线程上，而是可以在多个线程之间切换和轮转执行。这种模型允许更加高效地利用系统资源，提高并发性能。 GMP模型中的三个主要组件分别是：G（goroutine，协程）、M（machine，线程）和P（processor，处理器，不是指的cpu）。G表示协程，M表示操作系统线程，P表示Go运行时的调度器。在这个模型中，P负责将G调度到M上执行。一个P可以管理多个G，一个M可以关联到一个P。这种M:N的关系使得Go运行时可以在较少的操作系统线程上调度大量的协程，降低了线程切换的开销。 GMP调度机制 ","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:2:0","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"G G就是我们常说的goroutinue，G的本体是个结构体，保存着协程的上下文、状态、协程栈等信息，对应着src/runtime/runtime2.go:414的g结构体 type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback // param is a generic pointer parameter field used to pass // values in particular contexts where other storage for the // parameter would be difficult to find. It is currently used // in three ways: // 1. When a channel operation wakes up a blocked goroutine, it sets param to // point to the sudog of the completed blocking operation. // 2. By gcAssistAlloc1 to signal back to its caller that the goroutine completed // the GC cycle. It is unsafe to do so in any other way, because the goroutine's // stack may have moved in the meantime. // 3. By debugCallWrap to pass parameters to a new goroutine because allocating a // closure in the runtime is forbidden. param unsafe.Pointer atomicstatus atomic.Uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid uint64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine's stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. parkingOnChan atomic.Bool raceignore int8 // ignore race detection events tracking bool // whether we're tracking this G for sched latency statistics trackingSeq uint8 // used to decide whether to track this G trackingStamp int64 // timestamp of when the G last started being tracked runnableTime int64 // the amount of time spent runnable, cleared when running, only used when tracking lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr parentGoid uint64 // goid of goroutine that created this goroutine gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDo","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:2:1","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"M M（machine）对应于操作系统的一个线程，负责从队列中取出一个G（goroutine）进行执行。在同一时刻，一个M只能运行一个G。与传统模式不同，上下文切换由G完成而非M。M作为真正执行代码的实体，在执行完G的全部或部分任务后，会更新G的状态，并将其重新放入工作队列中，然后继续取出其他G执行。 假设我的机器是4核，我没有做额外的设置，M的数量就是4，在go程序进程启动的时候，会调用操作系统的APi创建4个线程分配给进程的runtime，这四个线程在程序运行过程中会被重复利用，而不会被回收，即使当前Go程序最多只有3个协程。这种机制有助于减少线程创建和销毁的开销，提高系统的并发性能。 假设四个线程的ID分别是1001、1002、1003和1004，它们在程序运行过程中是固定的。如果Go程序进程有50万个协程，协程切换非常迅速，那么这四个线程就像一个“永动机”，不停地执行这50万个G（goroutine）。 相比于传统的进程-线程模型，这种机制使得线程能够做更多的“功”，因为线程本身不需要进行上下文切换，而只是不停地取任务执行任务。上下文切换的工作交给了G（协程）来完成。这种灵活的调度机制使得Go能够更高效地利用系统资源，提高并发性能。 Goroutinue类似于空间换时间的策略，主要体现在两点，一是预先创建线程：Go运行时会根据CPU核心数预先创建一定数量的线程（M），虽然这可能导致某些线程闲置，从而造成资源浪费，但这种策略可以减少线程创建和销毁的开销，从而提高系统的并发性能；二是协程资源开销：相比于传统的进程-线程模型，协程本身也会占用一定的系统资源。虽然单个协程非常轻量，但是大量的协程仍会增加系统的开销。此外，如果协程被泄露，可能会导致系统资源得不到回收，从而可能引发内存溢出（OOM）。 ","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:2:2","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"P 在Go运行时中，P（Processor）处理器充当G（goroutine）和M（machine）之间的桥梁。需要注意的是，P并不是指CPU，而是一个结构体变量（src/runtime/runtime2.go:621），负责管理和调度G与M之间的关系。 M从队列中取G执行。这个队列实际上是属于P的。每个P都有一个本地队列，用于存储待执行的G。此外，还有一个全局队列，用于存储所有P的本地队列无法容纳的G。当使用go关键字创建一个协程时，该协程并不一定会立即执行，而是会被放入某个P的本地队列中。P的本地队列是一个长度为256的数组。如果协程数量过多，以至于所有P的本地队列都已满，那么新创建的协程将被放入全局队列中。全局队列类似于一个双链表，理论上长度是无限的。 通过这种机制，Go运行时可以灵活地调度大量协程在有限的线程上执行，从而实现高效的并发执行。P作为G和M之间的中介，确保了协程能够在不同的线程之间切换，充分利用系统资源。这种设计使得Go语言能够在高并发场景下表现出卓越的性能，同时简化了并发编程的复杂性。 type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache pcache pageCache raceprocctx uintptr deferpool []*_defer // pool of available defer structs (see panic.go) deferpoolbuf [32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. // // Note that while other P's may atomically CAS this to zero, // only the owner P can CAS it to a valid G. runnext guintptr // Available G's (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, more so than just managing the length // ourselves. len int buf [128]*mspan } // Cache of a single pinner object to reduce allocations from repeated // pinner creation. pinnerCache *pinner trace pTraceState palloc persistentAlloc // per-P to avoid mutex // The when field of the first entry on the timer heap. // This is 0 if the timer heap is empty. timer0When atomic.Int64 // The earliest known nextwhen field of a timer with // timerModifiedEarlier status. Because the timer may have been // modified again, there need not be any timer with this value. // This is 0 if there are no timerModifiedEarlier timers. timerModifiedEarliest atomic.Int64 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) // limiterEvent tracks events for the GC CPU limiter. limiterEvent limiterEvent // gcMarkWorkerMode is the mode for the next mark worker to run in. // That is, this is used to communicate with the worker goroutine // selected for immediate execution by // gcController.findRunnableGCWorker. When scheduling other goroutines, // this field must be set to gcMarkWorkerNotWorker. gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which the most recent // mark worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // statsSeq is a counter indicating whether this P is currently // writing any stats. Its value is even when not, odd when it is. statsSeq atomic.Uint32 // Lock for timers","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:2:3","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"Schedt 上面我们讨论了GMP模型中G（goroutine）、M（machine）和P（Processor）各自的概念和作用。然而，我们还需要一个调度器来完成G、M、P之间的整合和协调。在Go运行时中，这个调度器被称为Sched（同样是个结构体，对应着src/runtime/runtime2.go:774），负责完成上述的调度过程。 Sched调度器的主要职责包括： 确定将新创建的协程放入哪个P的本地队列或者全局队列。Sched会根据当前的负载情况和资源分配策略，将新创建的协程分配给合适的P。 确定M从哪个P的本地队列中取出G执行。Sched会监控各个P的本地队列，以确保M能够从合适的P中取出G执行。当一个M完成了一个G的执行后，Sched会将该G重新放入工作队列，并指导M继续从其他P的本地队列中取出G执行。上文提到的P的全局队列对应着schedt的runq字段。 通过Sched调度器的协调，Go运行时可以实现G、M、P之间的高效整合，从而在高并发场景下实现卓越的性能。 type schedt struct { goidgen atomic.Uint64 lastpoll atomic.Int64 // time of last network poll, 0 if currently polling pollUntil atomic.Int64 // time to which current poll is sleeping lock mutex // When increasing nmidle, nmidlelocked, nmsys, or nmfreed, be // sure to call checkdead(). midle muintptr // idle m's waiting for work nmidle int32 // number of idle m's waiting for work nmidlelocked int32 // number of locked m's waiting for work mnext int64 // number of m's that have been created and next M ID maxmcount int32 // maximum number of m's allowed (or die) nmsys int32 // number of system m's not counted for deadlock nmfreed int64 // cumulative number of freed m's ngsys atomic.Int32 // number of system goroutines pidle puintptr // idle p's npidle atomic.Int32 nmspinning atomic.Int32 // See \"Worker thread parking/unparking\" comment in proc.go. needspinning atomic.Uint32 // See \"Delicate dance\" comment in proc.go. Boolean. Must hold sched.lock to set to 1. // Global runnable queue. runq gQueue runqsize int32 // disable controls selective disabling of the scheduler. // // Use schedEnableUser to control this. // // disable is protected by sched.lock. disable struct { // user disables scheduling of user goroutines. user bool runnable gQueue // pending runnable Gs n int32 // length of runnable } // Global cache of dead G's. gFree struct { lock mutex stack gList // Gs with stacks noStack gList // Gs without stacks n int32 } // Central cache of sudog structs. sudoglock mutex sudogcache *sudog // Central pool of available defer structs. deferlock mutex deferpool *_defer // freem is the list of m's waiting to be freed when their // m.exited is set. Linked through m.freelink. freem *m gcwaiting atomic.Bool // gc is waiting to run stopwait int32 stopnote note sysmonwait atomic.Bool sysmonnote note // safepointFn should be called on each P at the next GC // safepoint if p.runSafePointFn is set. safePointFn func(*p) safePointWait int32 safePointNote note profilehz int32 // cpu profiling rate procresizetime int64 // nanotime() of last change to gomaxprocs totaltime int64 // ∫gomaxprocs dt up to procresizetime // sysmonlock protects sysmon's actions on the runtime. // // Acquire and hold this mutex to block sysmon from interacting // with the rest of the runtime. sysmonlock mutex // timeToRun is a distribution of scheduling latencies, defined // as the sum of time a G spends in the _Grunnable state before // it transitions to _Grunning. timeToRun timeHistogram // idleTime is the total CPU time Ps have \"spent\" idle. // // Reset on each GC cycle. idleTime atomic.Int64 // totalMutexWaitTime is the sum of time goroutines have spent in _Gwaiting // with a waitreason of the form waitReasonSync{RW,}Mutex{R,}Lock. totalMutexWaitTime atomic.Int64 } ","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:2:4","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"调度过程 在runtime2.go文件中有几个全局变量，分别是allm、gomaxprocs、ncpu、sched、newprocs、allp；下面分别解释一下它们的含义及作用。 在Go运行时中，以下变量和结构体用于管理和调度G（goroutine）、M（machine）和P（Processor）之间的关系： allm：一个指向M（machine）链表头部的指针。所有的M实例被组织成一个链表结构，以便在程序运行过程中方便地添加和删除M实例。 gomaxprocs：一个整数变量，表示允许同时运行的最大操作系统线程数（即M的数量）。默认情况下，它的值等于系统的CPU核心数。您可以通过设置GOMAXPROCS环境变量或使用runtime.GOMAXPROCS()函数来调整此值。 ncpu：一个整数变量，表示系统的CPU核心数。它在程序启动时被初始化，并在整个程序运行过程中保持不变。 sched：一个结构体，表示Go运行时的调度器。它负责协调G、M和P之间的关系，包括将新创建的协程分配给合适的P，以及指导M从合适的P的本地队列中取出G执行。 newprocs：一个整数变量，用于在调整gomaxprocs值时暂存新的最大并发线程数。当newprocs的值与gomaxprocs不同时，Go运行时会在下一个调度周期中更新gomaxprocs的值。 allp：一个切片，用于存储所有的P（Processor）实例。在程序运行过程中，P的数量可能会发生变化，例如，当您调整GOMAXPROCS值时。使用切片可以方便地调整P的数量，同时保持对所有P实例的引用。 所有的调度都是由sched变量完成的，在进程启动的时候，会把主线程分配到某个m上，当有新的goroutinue创建的时候会随机分配到p的某个队列上，如果选择的p满了，再选择其它的p，如果都满了则会放到全局队列上。总结一下调度过程： 创建G：当使用go关键字创建一个新的协程时，newproc函数会被调用。在newproc函数中，会创建一个新的G实例，并将其与待执行的函数关联。 将G放入队列：Sched调度器会将新创建的G尝试放入与当前正在执行的G关联的P的本地队列。如果当前P的本地队列已满，新创建的G会被放入全局队列。 M从队列中取G：Sched调度器会指导M从关联的P的本地队列中取出G执行。如果本地队列为空，M会尝试从全局队列或其他P的本地队列中偷取G。 执行G：M会执行取出的G，直到G执行完成或遇到阻塞操作（如I/O操作）。 G执行完成：当G执行完成后，Sched调度器会将G标记为已完成。如果G没有其他引用，它会在垃圾回收过程中被回收。与此同时，Sched调度器会指导M继续从关联的P的本地队列中取出下一个G执行。 G阻塞：当G遇到阻塞操作时（如IO操作、系统调用、sleep等），Sched调度器会将阻塞的G状态从Grunning切换到Gwaitin状态并放入原先所在的P（Processor）的本地队列或全局队列中，以便在阻塞操作完成后能够继续执行。同时，M会尝试从P的本地队列中取出另一个G执行。在这种情况下，Go运行时可能会创建一个新的M来执行其他G，以保持并发性能。 G解除阻塞：当阻塞操作完成后，Sched调度器会将阻塞G状态从Gwaiting状态切换到Grunnable状态，等待再次被调度到M上运行。 在整个调度过程中，Sched调度器负责管理G与P之间的交互，如将G放入P的本地队列以及从P的本地队列中取出G执行。同时，Sched调度器也负责协调P与M之间的交互，如指导M从关联的P的本地队列中取出G执行，以及在G阻塞时将G与M解除关联。 通过Sched调度器和GMP模型的协同工作，Go运行时可以实现高并发性能，同时简化了并发编程的复杂性。 ","date":"2023-09-17","objectID":"https://www.bardblog.cn/programing-language-gmp/:3:0","tags":["Go","GMP","Gorotinue","Thread"],"title":"GMP调度模型","uri":"https://www.bardblog.cn/programing-language-gmp/"},{"categories":["technology"],"content":"缓存淘汰算法LRU和LFU及其实现","date":"2023-09-16","objectID":"https://www.bardblog.cn/algorithm-cache-obsolescence/","tags":["Redis","Algorithm","Cache"],"title":"LFU和LRU缓存淘汰算法","uri":"https://www.bardblog.cn/algorithm-cache-obsolescence/"},{"categories":["technology"],"content":"前言 在日常开发过程中以及操作系统和许多开源项目中，为了提高性能，我们经常会使用缓存。缓存实际上是一种空间换时间的策略，通过将数据存储在快速访问的存储介质中，以减轻底层数据源的访问压力并提高系统性能。以日常开发为例，通常我们会将缓存数据存储在内存这种容量较小、速度快、价格较高的存储介质中。一个优秀的缓存系统通常需要考虑以下几个方面： 设置缓存占用内存空间上限，防止无限制增长导致服务内存溢出（OOM）。 分片策略，降低锁粒度。 选择合适的哈希算法，减少哈希碰撞。 使用singleflight策略，降低缓存击穿的风险。 采用合适的缓存淘汰策略，淘汰数据以释放存储空间。 设置缓存过期时间，减少内存空间占用并缩小数据不一致性的时间窗口。 使用高效的数据结构，平衡时间复杂度和空间复杂度。 监控告警，关注缓存击穿率和缓存命中率。 实现缓存持久化和预热。 本文将主要讨论两种常用的缓存淘汰策略的原理及其实现。 ","date":"2023-09-16","objectID":"https://www.bardblog.cn/algorithm-cache-obsolescence/:1:0","tags":["Redis","Algorithm","Cache"],"title":"LFU和LRU缓存淘汰算法","uri":"https://www.bardblog.cn/algorithm-cache-obsolescence/"},{"categories":["technology"],"content":"缓存淘汰算法 正如前面所提到的，为了避免内存溢出（OOM），缓存系统通常需要设置最大容量上限。这意味着缓存系统中存储的数据是有限的。假设我们现在有一个容量为10的缓存系统，任意时刻最多只有10条数据在缓存中。如果不考虑缓存设置过期时间，那么问题来了：是不是谁先占据这10个位置，其他数据就永远没有机会被放入缓存中？显然，这样的缓存系统并没有太大意义。 正如一个正常的社会应该有良好的阶级流动而非阶级固化一样，一个优秀的缓存系统中的数据也应该是流动的而非僵化的。为了实现这一目标，我们需要一种策略来清空部分数据，从而为新数据腾出空间。那么，我们应该如何淘汰数据呢？是随机淘汰，还是按照某种规则进行淘汰？这个策略就是本文要讨论的“缓存淘汰算法”。 ","date":"2023-09-16","objectID":"https://www.bardblog.cn/algorithm-cache-obsolescence/:2:0","tags":["Redis","Algorithm","Cache"],"title":"LFU和LRU缓存淘汰算法","uri":"https://www.bardblog.cn/algorithm-cache-obsolescence/"},{"categories":["technology"],"content":"LRU LRU（Least Recently Used，最近最少使用）是一种常用的缓存淘汰算法。它的核心思想是：当缓存空间不足时，优先淘汰最近最少使用的数据。LRU算法基于这样一个假设：最近访问过的数据在未来仍有较高的可能性被访问，因此应该将其保留在缓存中。 所谓“最近最少使用”，是指在一段时间内，某个数据相对于其他数据被访问的次数较少或者距离上次访问的时间较长。举个例子，假设你经常去北京、上海、天津和武汉这四个地方，但是最近一段时间你很长时间没有去武汉了。在这种情况下，武汉可以被视为“最近最少使用”的数据。对于缓存系统来说，它就会认为你好久没去武汉了，以后可能也不会去了，如果要去其它地方，那干脆把它从缓存中去掉吧，给新的数据腾位子。 这就是LRU缓存淘汰算法的基本思路。当缓存空间不足以容纳新数据时，它会选择最近最少使用的数据进行淘汰，从而为新数据腾出空间。这种策略有助于保留那些近期频繁访问的数据，从而提高缓存的命中率。当然，这种策略并非绝对准确，因为未来的访问模式可能会发生变化，但在实际应用中，LRU算法往往能够取得较好的性能。 为了实现这种效果，我们需要知道哪些数据是最近访问的，并按照某种顺序或权重记录缓存数据的优先级。当需要淘汰数据时，优先淘汰低优先级的数据。这就要求每次访问都需要让本次访问的数据优先级最高，避免被淘汰，实际上是一种贪心策略。 对于一个缓存系统来说，对外实际上主要提供两个能力：get和set。每次读取数据时，会将该数据的优先级设置为最高；每次写数据时，也会将数据放到最高优先级的位置。为了实现这一目标，我们通常会使用哈希表（HashMap），它能够在O(1)的时间复杂度内获取数据以及判断缓存是否存在。而对于要求数据通过优先级有序的场景，我们可以使用双链表这种数据结构。综合考虑，我们可以使用哈希表+双链表来实现LRU算法。 在这种实现中，哈希表负责快速查找缓存项，双链表负责维护缓存项的访问顺序。当访问或更新缓存时，我们可以在O(1)时间内通过哈希表找到对应的缓存项，然后将其移动到双链表的头部。当需要淘汰缓存时，我们可以直接移除双链表尾部的缓存项（最近最少使用的数据）。这样，我们就能在O(1)时间内完成缓存的读取、更新和淘汰操作，从而实现高效的LRU缓存淘汰算法。 优先级更新及淘汰过程 代码实现 package main import ( \"errors\" \"fmt\" \"sync\" ) func main() { const size = 20 l := NewLRU(size) for i := 0; i \u003c size+1; i++ { l.Add(fmt.Sprintf(\"%d\", i+1), (i+1)*100) } fmt.Println(l.Get(\"3\")) fmt.Println(l.Get(\"4\")) fmt.Println(l.Get(\"5\")) fmt.Println(l.Get(\"50\")) l.Iterator() for i := 0; i \u003c size+1; i++ { fmt.Printf(\"%p,%+v\\n\", l.dict[fmt.Sprintf(\"%d\", i+1)], l.dict[fmt.Sprintf(\"%d\", i+1)]) } } var ErrNotExist = errors.New(\"not exist\") type LRU struct { head *listNode tail *listNode dict map[string]*listNode size int mu sync.RWMutex } // NewLRU 新建一个LRU实例 func NewLRU(size int) *LRU { head := \u0026listNode{} tail := \u0026listNode{} head.right = tail tail.left = head return \u0026LRU{ head: head, tail: tail, dict: make(map[string]*listNode, size), size: size, mu: sync.RWMutex{}, } } func (l *LRU) Get(key string) (int, error) { l.mu.Lock() defer l.mu.Unlock() node := l.dict[key] if node == nil { return 0, ErrNotExist } l.cacheHit(node) return node.val, nil } func (l *LRU) Add(key string, val int) { l.mu.Lock() defer l.mu.Unlock() var newNode *listNode if _, ok := l.dict[key]; ok { newNode = l.dict[key] newNode.val = val l.cacheHit(newNode) return } newNode = \u0026listNode{ key: key, val: val, } var node *listNode if len(l.dict) \u003e= l.size { node = l.tail.left } if node != nil { l.tail.left = node.left node.left.right = l.tail delete(l.dict, node.key) } newNode.right = l.head.right l.head.right.left = newNode newNode.left = l.head l.head.right = newNode l.dict[key] = newNode } func (l *LRU) cacheHit(node *listNode) { node.left.right = node.right node.right.left = node.left node.right = l.head.right l.head.right.left = node node.left = l.head l.head.right = node } // Iterator 遍历LRU func (l *LRU) Iterator() { l.mu.Lock() defer l.mu.Unlock() t := l.head.right for ; t != l.tail; t = t.right { fmt.Printf(\"key:%d,val:%d \", t.key, t.val) } fmt.Println() } type listNode struct { left *listNode right *listNode key string val int } ","date":"2023-09-16","objectID":"https://www.bardblog.cn/algorithm-cache-obsolescence/:2:1","tags":["Redis","Algorithm","Cache"],"title":"LFU和LRU缓存淘汰算法","uri":"https://www.bardblog.cn/algorithm-cache-obsolescence/"},{"categories":["technology"],"content":"LFU 前面提到，假设你可能会经常访问北京、上海、天津和武汉这四个城市。有一段时间内没去武汉，使用LRU淘汰策略把这个数据从缓存中剔除。这看似合理，但实际上可能存在误伤。因为没去武汉的原因可能是以后不会再去了，也可能是这段时间内遇到了突发情况，比如买不到票或者武汉天气不太好。实际上，在最近这段时间之前，你去武汉的频率可能是最高的。在这种情况下，淘汰武汉这个数据可能并不合适。这就引申出另外一种缓存淘汰策略——LFU，它会记录每个数据的访问次数，并按照访问次数排序，将访问次数最低的数据视为低优先级数据。 LFU（Least Frequently Used，最不经常使用）是一种常用的缓存淘汰算法。它的核心思想是：当缓存空间不足时，优先淘汰访问频率最低的数据。LFU算法基于这样一个假设：访问频率较低的数据在未来被访问的可能性也较低，因此将其从缓存中移除。 为了实现LFU算法，我们需要记录每个数据项的访问频率。通常，可以使用哈希表来存储缓存项及其对应的访问频率。当访问或更新缓存时，我们需要更新对应数据项的访问频率。当需要淘汰缓存时，我们需要找到访问频率最低的数据项并将其移除。为了高效地找到访问频率最低的数据项，我们可以使用一种特殊的数据结构，如最小堆或者使用多个双链表，每个双链表代表一个访问频率，链表中的缓存项按照访问时间排序。 相较于LRU算法，LFU算法更加关注数据项的访问频率，而不仅仅是最近的访问时间。这使得LFU算法在某些场景下能够更好地预测未来的访问模式，从而提高缓存的命中率。然而，LFU算法的实现通常比LRU算法更复杂，且在数据访问频率分布较为平均的场景下，LFU算法的优势可能不会非常明显。 根据访问频率更新及淘汰过程 代码实现 package main import ( \"fmt\" \"sort\" \"sync\" ) func main() { const size = 20 l := NewLFU(size) for i := 0; i \u003c size; i++ { l.Add(i+1, (i+1)*100) } fmt.Println(l.Get(3)) fmt.Println(l.Get(4)) fmt.Println(l.Get(5)) fmt.Println(l.Get(4)) l.Add(22, 2200) l.Add(23, 2300) l.Add(24, 2400) l.Add(23, 23000) // l.Iterator() const ( shardNum = 256 eachShardCapacity = 1000 ) fmt.Println(\"======cache\") cache := NewLocalCache(shardNum, eachShardCapacity) for i := 0; i \u003c shardNum*eachShardCapacity; i++ { cache.Add(i+1, (i+1)*10) } for i := 0; i \u003c shardNum \u0026\u0026 i*10+10 \u003c shardNum; i++ { fmt.Println(len(cache.cacheList[i*10+10].dict)) } } type LocalCache struct { cacheList []LFU shardNum int } func NewLocalCache(shardNum int, eachSharCapacity int) LocalCache { cacheList := make([]LFU, shardNum) for i := 0; i \u003c len(cacheList); i++ { cacheList[i] = NewLFU(eachSharCapacity) } return LocalCache{ cacheList: cacheList, shardNum: shardNum, } } func (l *LocalCache) Add(key, val int) { index := hash(key) % l.shardNum l.cacheList[index].Add(key, val) } func (l *LocalCache) Get(key int) int { index := hash(key) % l.shardNum return l.cacheList[index].Get(key) } // LFU is a structure for LFU cache. type LFU struct { dict map[int]*listNode // dict stores the key-value pairs. freqDict map[int]*freqNode // freqDict stores the frequency of each key. minFrequency int // minFrequency stores the minimum frequency. capacity int // capacity is the capacity of the cache. mu sync.Mutex // mu is used for ensuring thread safety. } // NewLFU creates a new LFU cache. func NewLFU(capacity int) LFU { return LFU{ dict: make(map[int]*listNode, capacity), freqDict: make(map[int]*freqNode, capacity), minFrequency: 0, capacity: capacity, mu: sync.Mutex{}, } } // listNode is a node in the doubly linked list. type listNode struct { left, right *listNode // left and right are pointers to adjacent nodes. key, val int // key and val are the key and value of the node. accessTimes int // accessTimes is the number of times the node has been accessed. } // freqNode is a node in the frequency list. type freqNode struct { head, tail *listNode // head and tail are pointers to the head and tail of the list. size int // size is the number of nodes in the list. } // Add adds a key-value pair to the cache. func (l *LFU) Add(key, val int) { l.mu.Lock() // Lock the cache. defer l.mu.Unlock() // Unlock the cache when the function returns. node, ok := l.dict[key] if ok { node.val = val l.hitIncrease(node) return } if len(l.dict) == l.capacity { freq := l.freqDict[l.minFrequency] minNode := freq.tail.left minNode.left.right = freq.tail freq.tail.left = minNode.left freq.size -= 1 delete(l.dict, minNode.key) if freq.size == 0 { delete(l.freqDict, l.minFrequency) } } l.minFrequency = 1 node = \u0026listNode{ key: key, val: val, accessTimes: 1, } freq, ok := l.freqDict[node.accessTimes] if !ok { freq = newFreqNode() l.freqDict[node.accessTimes] = freq } freq.size += 1 freq.add(node) l.dict[key] = node } // Get gets the value of a key from the cache. func (l *LFU) Get(key int) int { l.mu.Lock() // Lock the cache. defer l.mu.Unlock() // Unlock the cache when the function returns. node, ok := l.dict[key] if !ok { return -1 } l.hitIncrease(node) return node.val } // hitIncrease increases the access ti","date":"2023-09-16","objectID":"https://www.bardblog.cn/algorithm-cache-obsolescence/:2:2","tags":["Redis","Algorithm","Cache"],"title":"LFU和LRU缓存淘汰算法","uri":"https://www.bardblog.cn/algorithm-cache-obsolescence/"},{"categories":["technology"],"content":"负载均衡算法 在分布式系统中，一般来说会有多台机器，机器可能会分布在不同的集群，客户端的一个请求经过服务注册中心或者网关，注册中心或者网关会根据负载均衡算法将本次请求分发到某台具体的服务器，负载均衡算法主要用于分配网络或计算资源，以优化响应时间和避免过度负载任何一个资源。以下是一些常见的负载均衡算法： 轮询（Round Robin）：这是最简单的负载均衡算法，它将请求按顺序分配给服务器。当到达最后一个服务器时，算法会返回到队列的顶部并重新开始。 加权轮询（Weighted Round Robin）：这是轮询的一个变种，它考虑到了服务器的处理能力。每个服务器都被分配一个权重，权重较高的服务器将接收更多的请求。 最少连接（Least Connections）：这种算法将新的请求分配给当前连接数最少的服务器。这对于处理时间较长的请求非常有效。 加权最少连接（Weighted Least Connections）：这是最少连接算法的一个变种，它考虑到了服务器的处理能力。每个服务器都被分配一个权重，权重较高的服务器将接收更多的请求。 随机（Random）：这种算法将请求随机分配给服务器。 最短响应时间（Least Response Time）：这种算法将请求分配给响应时间最短的服务器。 普通哈希（Hash）：这种算法根据源IP地址或者请求入参的哈希值来分配请求。这样可以保证来自同一源IP地址或者同一个请求总是被分配给同一台服务器。 一致性哈希（Consistent Hashing）：对普通Hash算法的一个改进，这种算法主要用于分布式系统，它可以在服务器集群的数量发生变化时，最小化重新分配的数据。 设想我们有这样一个场景：有一个分布式服务，我们需要为这个服务构造一个本地缓存，当服务的机器数很多的时候，同一个key可能在多台机器上都会有缓存，如果要缓存的数据量很大的时候，同一台机器上key过多可能会导致机器内存占用率过高，严重的可能会发生OOM，这就要求缓存的key散列的分布在不同的机器上，减少单台机器的负载，需要构造一个请求入参和机器的映射关系，让相同的请求打到相同的机器上。应该采用上述何种算法提高缓存的命中率并减少缓存占用空间呢？1-6的算法，一个请求打到哪台服务器随机性很大，7-8都是hash算法，如果把请求入参hash，理论上可以保证同样的请求达到同样的机器上的。但是普通的hash算法的问题在于，当服务发生扩缩容的时候，会导致请求倾斜，请求不够均匀离散。 hash负载均衡 如上图所示，假设这个服务有A/B/C/D四台机器，每台机器负责一部分请求，和普通的hash算法不同的是，一致性hash把一个结点化整为零拆分成多个虚拟子结点，所有机器的子结点构成了一个环，按照子结点负责的hash值进行排序，这样做的主要有两个好处：一是让请求更加离散最大程度上减少请求聚集避免单点承载过重，二是在发生扩缩容请求调度的时候能够以较小的代价完成调度的过程。 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:1:0","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"代码实现 package main import ( \"crypto/rand\" \"encoding/hex\" \"fmt\" \"hash/fnv\" \"net\" \"sort\" \"sync\" ) const ( keySize = 1000 traceIDLen = 16 ringSize = 100 ) func main() { hr := NewHashRing([]ServerNode{ { Name: \"grpc.app.server1.service1\", Weight: 0.89, }, { IP: net.ParseIP(\"123.33.32.1\"), Port: 8932, Weight: 0.73, }, { IP: net.ParseIP(\"123.33.32.1\"), Port: 8933, }, { IP: net.ParseIP(\"234.65.32.3\"), Port: 8932, Weight: 1, }, { IP: net.ParseIP(\"231.23.32.11\"), Port: 32322, Weight: 1.11, }, }) keys := make([]string, keySize*2) for i := 0; i \u003c keySize; i++ { keys[i] = generateTraceID() keys[2*keySize-i-1] = keys[i] } for _, key := range keys { fmt.Printf(\"%s:%s\\n\", key, hr.GetNode(key)) } fmt.Println(\"AddNodes============================================================\") hr.AddNodes( ServerNode{IP: net.ParseIP(\"132.232.123.223\"), Port: 1923, Weight: 0.91}, ServerNode{Name: \"trpc.app.server2.service1\", Weight: 1.21}, ) for _, key := range keys { fmt.Printf(\"%s:%s\\n\", key, hr.GetNode(key)) } fmt.Println(\"RemoveNodes============================================================x\") hr.RemoveNodes(hr.GetNode(keys[0]), hr.GetNode(keys[1]), hr.GetNode(keys[3])) for _, key := range keys { fmt.Printf(\"%s:%s\\n\", key, hr.GetNode(key)) } } // HashRing 哈希环 // nodes 真实结点 // virtualNodes n个虚拟节点指向一个实际节点,一个实体节点变成n个虚拟结点，均匀打散。 type HashRing struct { nodes map[string]ServerNode virtualNodes map[uint32]ServerNode sortedHashes []uint32 mu sync.RWMutex } // ServerNode 服务器结点信息 type ServerNode struct { Name string // 服务名 IP net.IP // ip地址 Port uint16 // 端口 Weight float32 // 权重 } // NewHashRing 新建一个hash环 func NewHashRing(nodes []ServerNode) *HashRing { ns := make(map[string]ServerNode, len(nodes)) for _, nd := range nodes { ns[nd.String()] = nd } hr := \u0026HashRing{nodes: ns, virtualNodes: map[uint32]ServerNode{}} hr.virtualNodes = hr.generateVirtualNodes() hr.sortedHashes = hr.genSortedHashes() hr.mu = sync.RWMutex{} return hr } // AddNodes 添加结点 func (h *HashRing) AddNodes(nodes ...ServerNode) { h.mu.Lock() defer h.mu.Unlock() for _, node := range nodes { if _, ok := h.nodes[node.String()]; ok { continue } h.nodes[node.String()] = node h.addVirtualNodes(node) } h.sortedHashes = h.genSortedHashes() } // RemoveNodes 移除结点 func (h *HashRing) RemoveNodes(nodes ...ServerNode) { h.mu.Lock() defer h.mu.Unlock() for _, node := range nodes { if _, ok := h.nodes[node.String()]; !ok { continue } delete(h.nodes, node.String()) h.deleteVirtualNodes(node) } h.sortedHashes = h.genSortedHashes() } // GetNode 获取结点 func (h *HashRing) GetNode(key string) ServerNode { h.mu.RLock() // Use read lock instead of write lock defer h.mu.RUnlock() if len(h.virtualNodes) == 0 { return ServerNode{} } hashValue := hash(key) if h.sortedHashes[len(h.sortedHashes)-1] \u003c hashValue { return h.virtualNodes[h.sortedHashes[0]] } i, j := 0, len(h.sortedHashes)-1 for i \u003c j { mid := i + (j-i)/2 if h.sortedHashes[mid] \u003e= hashValue { j = mid } else { i = mid + 1 } } if h.sortedHashes[i] \u003e= hashValue { return h.virtualNodes[h.sortedHashes[i]] } return h.virtualNodes[h.sortedHashes[0]] } func (h *HashRing) generateVirtualNodes() map[uint32]ServerNode { virtualNodes := make(map[uint32]ServerNode) for _, node := range h.nodes { for i := 0; i \u003c int(ringSize*node.Weight); i++ { virtualNode := fmt.Sprintf(\"%s#%d\", node, i) virtualNodes[hash(virtualNode)] = node } } return virtualNodes } func (h *HashRing) addVirtualNodes(node ServerNode) { for i := 0; i \u003c int(ringSize*node.Weight); i++ { virtualNode := fmt.Sprintf(\"%s#%d\", node, i) h.virtualNodes[hash(virtualNode)] = node } } func (h *HashRing) deleteVirtualNodes(node ServerNode) { for i := 0; i \u003c int(ringSize*node.Weight); i++ { delete(h.virtualNodes, hash(fmt.Sprintf(\"%s#%d\", node, i))) } } func (h *HashRing) genSortedHashes() []uint32 { hashes := make([]uint32, 0, len(h.virtualNodes)) for node := range h.virtualNodes { hashes = append(hashes, node) } sort.Slice(hashes, func(i, j int) bool { return hashes[i] \u003c hashes[j] }) return hashes } func hash(key string) uint","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:2:0","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"调度过程 在服务扩容或缩容的过程中，请求的转移是不可避免的。这个过程类似于Kafka的rebalance操作，即重新调度资源分配。然而，Kafka的rebalance过程的一个缺点是它相对较慢，这是由于Kafka的高吞吐量和高可用性所决定的。一致性哈希算法的优点在于整个rebalance过程会非常快，这样可以更好地应对服务请求量波动导致的扩缩容。 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:3:0","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"服务扩容 假设我们现在有A、B、C和D四台机器，通过一致性哈希算法，每台机器负责一部分的请求。当流量增加或出现热点问题导致请求量增加时，服务会自动扩容出一台新的机器E。在这个过程中，调度机制会首先计算E机器对应的虚拟节点负责的哈希范围，然后通过插入排序的方式，将新的虚拟节点插入到已有的哈希环中。最后，更新服务的路由信息，使得新的请求逐步平滑地从原有节点迁移到新扩容出来的节点。整个过程如下： 计算新机器E对应的虚拟节点负责的哈希范围。 将新的虚拟节点插入到已有的哈希环中，使用插入排序的方式。 更新服务的路由信息，使得新的请求逐步平滑地从原有节点迁移到新扩容出来的节点。 扩容调度过程 通过这种方式，一致性哈希算法可以快速地进行服务扩容，更好地应对服务请求量波动导致的扩缩容。 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:3:1","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"服务缩容 上面介绍了扩容的过程，缩容过程与扩容相似。假设B机器因为长期低负载和较小的请求量触发了缩容策略，导致机器被回收。在这种情况下，调度机制会在哈希环中移除所有与B机器相关的虚拟节点，并更新路由信息。此时，原先B服务器虚拟节点负责的请求哈希范围会均匀地分散到其他机器的虚拟节点上。 由于整个哈希环中，如果哈希算法足够均匀，那么A、B、C和D四台机器对应的虚拟节点也是离散分布的。这样，在缩容后，剩下的三台机器不会出现某台机器承载过重的情况，从而避免了雪崩效应。通过这种方式，一致性哈希算法在服务缩容过程中能够快速地进行资源调度，确保系统的稳定性和可用性。 缩容调度过程 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:3:2","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"小结 一致性hash算法调度过程的关键点如下： 一致性哈希算法在服务扩容和缩容过程中能够快速地进行资源调度，以应对服务请求量波动导致的扩缩容。 在扩容过程中，新的虚拟节点会被插入到已有的哈希环中，并更新路由信息，使得新的请求逐步平滑地从原有节点迁移到新扩容出来的节点。 在缩容过程中，被回收机器的虚拟节点会从哈希环中移除，并更新路由信息，使得原先负责的请求哈希范围均匀地分散到其他机器的虚拟节点上。 一致性哈希算法通过离散分布的虚拟节点，确保在扩缩容过程中不会出现某台机器承载过重的情况，从而避免了雪崩效应。 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:3:3","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"实际应用 一致性哈希算法在实际应用中有很多场景，以下是一些常见的应用： 分布式缓存：在分布式缓存系统（如Redis、Memcached）中，一致性哈希算法被用于将缓存数据分布在多个缓存节点上。当缓存节点发生扩容或缩容时，一致性哈希算法能够保证数据重新分布的过程中，尽量减少数据迁移的数量，从而降低缓存失效的概率。 负载均衡：在分布式系统中，负载均衡器（如Nginx、HAProxy）可以使用一致性哈希算法将客户端请求分发到不同的服务器上。这样，在服务器扩容或缩容时，可以保证客户端请求的重新分配过程更加平滑，避免某些服务器过载。 分布式存储：在分布式存储系统（如Cassandra、HBase）中，一致性哈希算法被用于将数据分片存储在多个节点上。当存储节点发生扩容或缩容时，一致性哈希算法能够保证数据重新分布的过程中，尽量减少数据迁移的数量，从而降低数据不一致的风险。 分布式锁：在分布式锁系统（如ZooKeeper、etcd）中，一致性哈希算法可以用于将锁资源分布在多个锁服务器上。这样，在锁服务器扩容或缩容时，可以保证锁资源的重新分配过程更加平滑，避免某些锁服务器过载。 一致性哈希算法在实际应用中有很多场景，主要用于解决分布式系统中的数据分布、负载均衡和动态扩缩容等问题。 ","date":"2023-07-09","objectID":"https://www.bardblog.cn/consistent-hash/:4:0","tags":["hash","algorithm","load balance"],"title":"一致性hash算法","uri":"https://www.bardblog.cn/consistent-hash/"},{"categories":["technology"],"content":"概念 跳表是一种很特殊的数据结构，可以把跳表理解为一个多层链表，每一层都是一个有序链表，链表之间通过指针连接，并且最底层的那个链表保存跳表完整的元素，跳表示意图如下： 跳表示意图 可以看到除了最后一层链表，每一层链表元素都有可能缺失。 小结一下跳表的基本特征： 每一层都是一个按照结点的score有序的链表 链表结点key全局唯一，score可以相同 不同层链表相同结点之间通过指针相连 最底层链表含有跳表所有元素 由此可以抽象化出跳表的数据结构： // skipList 跳表数据结构 // Data 链表结点数据 // next 指向下一个节点指针，同一层链表结点按照Score非递减 // down，与下一层连接指针，当前节点p p!=nil\u0026\u0026p.down!=nil 满足 p.Data==p.down.Data type skipList struct { Data Data next *skipList down *skipList } // Data 数据类型 type Data *Element // Element 链表结点格式 // Key: zSet的成员key，全局唯一 // Score: zSet的成员对应的分数，可以一样 type Element struct { Key string Score int } ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:1:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"插入流程 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:2:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"删除流程 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:3:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"更新流程 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:4:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"查询流程 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:5:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"代码实现 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:6:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"实际应用 ","date":"2023-07-06","objectID":"https://www.bardblog.cn/redis-zset-implemention/:7:0","tags":["redis","algorithm","skiplist","zSet"],"title":"zset分析与实现","uri":"https://www.bardblog.cn/redis-zset-implemention/"},{"categories":["technology"],"content":"关于channel的底层实现","date":"2023-07-01","objectID":"https://www.bardblog.cn/programing-language-channel/","tags":["Go","Queue"],"title":"Golang中channel底层实现原理","uri":"https://www.bardblog.cn/programing-language-channel/"},{"categories":["technology"],"content":"前言 并发编程是日常开发中经常需要使用到的，在Java中jdk提供了功能丰富的 并发库和并发原语支持，包括线程池、各种锁机制，并发安全的数据结构等，开发者可以以比较低的成本来进行并发编程。但是在golang里面，更并发相关的一些组件或者说能力相对来说就没有Java中那么丰富了，比如说golang中就没有提供线程池这个能力。golang遵循的哲学是使用通信来共享内存，而不是使用共享内存来通信。，简单来说在golang中多线程之间要进行数据共享的时候，并不是通过共享内存，去对共享内存并发读写实现的，golang提供了一种名为channel的能力，多协程之间通过channle传输数据做并发控制和数据同步。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/programing-language-channel/:1:0","tags":["Go","Queue"],"title":"Golang中channel底层实现原理","uri":"https://www.bardblog.cn/programing-language-channel/"},{"categories":["technology"],"content":"介绍MySQL的核心概念","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"MySQL 介绍MySQL的一些核心概念以及它们的底层实现,以下都是基于MySQL的InnoDB存储引擎。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:0:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"SQL语句执行流程 我们刚开始学习SQL的时候，第一个学的就是select语句了，以下就是一条最简单的查询语句: // 在student表中查询一条id为1的记录 select * from student where id=1; 那么执行这条SQL语句的全流程是什么呢？MySQL内部执行这条简单的SQL语句都做了哪些事，内部发生了什么呢？带着疑问开始学习MySQL，了解MySQL的内部架构。 先从全局的角度来看一条SQL语句的执行流程，从图中可以看到SQL语句从客户端到到数据存储整个流程以及MySQL的架构所包含的模块。 MySQL执行流程 可以看到MySQL内部分为两层，Server层和存储引擎层。 Server层负责建立和客户端连接、分析、优化和执行SQL语句。Server层和存储引擎无关，MySQL的核心模块都是在Server层实现，包括连接器、解析器、预处理器、优化器、执行器，此外MySQL的内置函数和所有跨存储引擎的功能都是在Server层实现/。 存储引擎层负责数据的提取和存储。存储引擎有多重，常见的有InnoDB、MyISAM、Memory，提供给Server层的接口都是一样的，只是具体实现不同。本文主要就InnodDB存储引擎展开，InnoDB也是MySQL的默认存储引擎。我们熟悉的MySQL的一些概念，如索引、事务、锁等都是在存储引擎层实现的，InnoDB的索引类型是B+树，我们在数据库表中创建的主键索引、联合索引、普通索引等都是用的B+树索引 以上介绍了一下MySQL的整体架构，总的架构来说“不算复杂”，就Server层和存储引擎层，下面就具体细节展开。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"连接器 如果想要对MySQL进行增删改查操作，首先肯定是要和MySQL建立连接才能继续接下来的操作，一般使用如下命令和MySQL服务建立连接。 # -h 指定域名或者ip地址 # -u 指定用户名 # -p 指定密码，从风险角度考量一般不写死，而是在执行命令后手动在控制台输入 mysql -h ip -u user -p 如： mysql -h 192.168.1.111 -u root -p 因为MySQL的的传输层协议是基于TCP的，所以建立连接的过程需要经过TCP三次握手。如果MySQL服务器运行正常，在建立TCP连接后，会验证我们的用户名和密码是否正确，如果用户名或者密码不对，就会报错：Access denied for user。如果用户名和密码都是ok的，连接器就会根据用户名查询改用户具有的权限，把权限保存在内存里，在改次连接断开之前，即便是管理员修改了用户的权限，也不会影响用户在本次连接的权限，只会在下次建立连接的时候才会使用新的权限，在本次连接生命周期中，用户的所有读写操作的权限都是基于认证的时候保存在内存的权限。 可以使用如下命令查看当前mysql服务器建立的脸颊情况 mysql\u003e show processlist; +----------+------+--------------------+-------------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----------+------+--------------------+-------------+---------+------+-------+------------------+ | 10773010 | root | 10.99.17.131:21086 | NULL | Sleep | 210 | | NULL | | 10773094 | root | 10.99.17.131:23980 | mysql_learn | Sleep | 72 | | NULL | | 10773150 | root | 10.99.17.131:25924 | NULL | Query | 0 | init | show processlist | +----------+------+--------------------+-------------+---------+------+-------+------------------+ 3 rows in set (0.02 sec) 可以看到,有三个用户名为root的用户和MySQL服务建立了连接，其中Id为10773010的用户使用的db是空而且Commond的值是Sleep，意味着该用户执行连接命令后没有再执行过其它任何命令，并且空闲等待的时间为210s（Time列） 那么这个空闲等待时间会一直无限递增吗？换句话说MySQL连接会一直保存着吗？ 肯定是不可能的，不可能我一年前建立的一个连接然后忘了啥都没干，但是MySQL还记着一直给我保存着，显然这是不可能的（就好比去餐厅吃饭，预约了一个座位，超过一定时间没去肯定会给你取消的），MySQL也有类似的机制，如果一个连接长期在哪空转啥都不干，超过一定时间内就会自动断开，这个断开时间（最大空闲时常）是由 wait_timeout这个参数控制的，默认的是26060=7200s。 mysql\u003e show variables like 'wait_timeout'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | wait_timeout | 7200 | +---------------+-------+ 1 row in set (0.03 sec) 如果我们看某个连接不爽，也可以使用 kill connection +Id命令手动kill这个连接，我现在想要干掉10773010这个连接，只需要执行如下命令： mysql\u003e kill connection +10773010; Query OK, 0 rows affected (0.02 sec) mysql\u003e show processlist; +----------+------+--------------------+-------------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----------+------+--------------------+-------------+---------+------+-------+------------------+ | 10773094 | root | 10.99.17.131:23980 | mysql_learn | Sleep | 895 | | NULL | | 10773150 | root | 10.99.17.131:25924 | NULL | Query | 0 | init | show processlist | +----------+------+--------------------+-------------+---------+------+-------+------------------+ 2 rows in set (0.03 sec) mysql\u003e 可以看到10773010这个连接已经被kill掉了 可以无限和MySQL服务器建立连接吗？ 就像任何资源都是有上限的，MySQL的连接也是宝贵的资源，肯定不会也不能无限提供，就像最大空闲市场是由wait_timeout这个参数控制的一样，最大连接数是由 max_connections参数控制的 mysql\u003e show variables like 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 2500 | +-----------------+-------+ 1 row in set (0.03 sec) mysql\u003e 比如我的MySQL服务器的最大连接数是2500，意味着在同一时刻最多只能保持2500个连接，超过这个值，系统会拒绝接下来的连接请求，并且报错Too many connections。 我们知道HTTP协议是基于TCP协议的，HTTP有长连接和短连接，同样的MySQL也有长连接和短连接。 长连接：顾名思义，存活周期很长的连接，客户端在和MySQL建立连接后，每次执行完一条SQL语句，连接不会马上释放，而是保存着，下次再执行SQL语句不用重复建连了，而是可以复用这条连接。 短连接：故名思义，存活周期较短的连接，客户端在和MySQL建立连接后，每次执行完一条SQL语句，连接马上释放，下次再执行SQL语句需要重新建连。 # 长连接 经过tcp三次握手和MySQL建立连接 执行sql1 执行sql2 执行sql3 .... 执行sqln 经过tcp四次挥手和MySQL断开链接。 # 短连接 经过tcp三次握手和MySQL建立连接 执行sql1 经过tcp四次挥手和MySQL断开链接。 经过tcp三次握手和MySQL建立连接 执行sql2 经过tcp四次挥手和MySQL断开链接。 经过tcp三次握手和MySQL建立连接 执行sql3 经过tcp四次挥手和MySQL断开链接。 .... 经过tcp三次握手和MySQL建立连接 执行sqln 经过tcp四次挥手和MySQL断开链接。 可以看到长连接和短连接各有优劣。 长连接的好处在于不用每次执行SQL语句都建立连接，做到资源复用，而且可以降低SQL语句耗时（省去建立连接的三次握手过程）；坏处在于连接长期得不到释放，连接是需要占用MySQL的系统资源的，如果长连接累积的很多，可能会导致MySQL系统OOM，所以最大连接数不能配置的太高。 短连接的好处在于每次执行完SQL语句连接都被释放掉了，降低MySQL系统负载，坏处是每次执行SQL语句都需要建立连接，会增加SQL语句执行耗时。 在实际开发过程中，一般推荐使用长连接，因为可以减少建连和断连的过程，但是长连接过多可能会导致MySQL系统高负载，导致服务异常重启。 长连接长期不释放，MySQL系统内存会占用很大，如何解决？ 一般来说，有以下几种解决方式： 设置合理的超时时间在MySQL服务器和客户端之间建立长连接时，可以设置合理的超时时间。通过配置wait_timeout和interactive_timeout参数，可以控制连接在闲置一段时间后自动关闭。这样可以确保长时间不活跃的连接被释放，释放相关的资源。 使用连接池使用连接池管理连接是一种常见的解决方案。连接池可以维护一组预先创建的连接，并在需要时分配给客户端。连接池会复用连接，避免频繁地创建和销毁连接，从而减少资源消耗。连接池通常还提供连接的管理和监控功能，可以根据需求配置连接的最大数量、超时时间等参数。 显式关闭连接在编写应用程序代码时，确保在不再需要连接时显式关闭连","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:1","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"查询缓存 建立连接之后，客户端就可以向MySQL服务器发送执行SQL了，MySQL服务器收到SQL语句后首先判断这个SQL语句是不是查询语句（根据SQL语句第一个字段是不select来判断），如果是查询语句的话，MySQL就会先去查询缓存里面查找是否有这个SQL查询语句的缓存结果，如果有的话，直接就返回给客户端，不进行下一步，缓存是以key:value形式存储的，key是SQL查询语句，value是查询结果。 看起来很美好，但是需要关注一下这里的缓存命中以及有效率的问题，在一般情况下，MySQL的查询缓存失效率是很高的，因为只要MySQL表中有数据更新，缓存就会失效。比如我要查询 select * from student where id=1; 第一次查询这条记录后，MySQL会把id=1的查询结果刷到缓存中，但是如果MySQL执行了更新语句，这个缓存就会失效。 比如MySQL更新了id=2的数据 update student set name='张三' where id=2; 我们可能会在想，为啥MySQL做的这么粗暴呢，更新id=2不影响id=1的结果啊，为啥要把id=1的缓存干掉？因为MySQL不知道更新id=2这条记录是否会影响id=1的这条记录，或者说想要知道是否会影响的代价太大了(很难判断是否会有影响，如果真要判断，付出的代价相比于缓存的收益更大，得不偿失)，MySQL为了保证数据的一致性，干脆只要一有更新操作就让缓存失效。 从上面的分析可以知道，这个缓存好像没啥用，因为即便是读多写的场景，也不能完全不写，而只要有写操作，就让表的所有缓存失效，代价是很大的，成本和收益不成正比，所以在MySQL8.0的版本，去掉了查询缓存这个功能。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:2","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"解析器 一条SQL语句如果能够执行成功，首先肯定是符合MySQL的SQL语法规范的，这个规范可以理解为我们和MySQL定的规则，我们遵循这个规则来写SQL语句，MySQL同样也要遵循规则去解析执行我们写的SQL语句，不可能说我们随便写一段字符串，MySQL也去给我们执行。在执行SQL语句之前，MySQL需要理解我们这条SQL语句是干嘛的，是增、删、改还是查，SQL语句涉及到哪些表，哪些表字段？这些都需要也可以根据语法规则去提取出来的，这实际上就是解析器要做的事。 解析器会做两件事： 第一件事： 语法分析MySQL会根据和我们协定的语法规则检查SQL语句是否有语法错误，如果有语法错误，会直接报错You have an error in your SQL syntax,比如我们执行如下语句 mysql\u003e slect * from friend where id=1; ERROR 2013 (HY000): Lost connection to MySQL server during query No connection. Trying to reconnect... Connection id: 10788396 Current database: mysql_learn ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'slect * from friend where id=1' at line 1 mysql\u003e 把select打成了slect，MySQL根据语法规则校验这条SQL语句是不符合语法规范的，就直接报错了。这个类似于我们后台开发常用的参数校验。 第二件事： 词法分析：不管是多复杂的SQL语句总是有规律可循的，比如where关键字后面肯定是查询条件，from关键字后面是表名， MySQL实现了词法解析器，根据SQL语句提取出来表名、SQL类型、表名、字段名，where查询条件等，做好准备工作给到后面模块使用。 需要注意的是上面说到语法检查和词法分析是在解析器做的，但是判断表名和字段名是否存在这些并不是在解析器层做的，可以理解为解析器这一层都是本地逻辑，不涉及到网络或者API调用。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:3","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"预处理器 SQL语句经过解析器后，就可以判断这条SQL语句是可能可以被执行的，为什么是可能呢？因为经过解析器只能说明这条SQL语句语法是没问题的以及提取了表名等需要执行的SQL语句包含的关键信息，但并不代表这个SQL语句就一定能执行成功，就像上面说的，如果SQL语句查询一张不存在的表，那么肯定不会执行成功的。预处理器主要干两件事： 检查解析器从SQL语句中提取出来的表名、字段名是否存在。 将select *的*替换成实际的字段名 这一步就不像解析器那样是纯本地逻辑的，在预处理阶段，需要先读取表的信息，进而检查表名、字段名是否存在，以及将 *替换成实际的字段名，这就涉及到API调用了。 我们执行如下SQL语句报错，这个报错其实是预处理器返回的。 mysql\u003e select * from frined where id=1; ERROR 1146 (42S02): Table 'mysql_learn.frined' doesn't exist mysql\u003e ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:4","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"优化器 经过解析器和预处理器后，SQL语句来到了优化器，严格来说，到了优化器，不能再叫SQL语句了，因为经过前面两位大哥的处理之后，SQL语句已经面目全非，到了优化器这一层，可以确定这条SQL语法是完全合法的，既没有语法错误，表名和字段名也都存在。那为啥还要经过优化器处理，直接丢给执行器执行不就行了吗？肯定不行，如果这么无脑的话，那MySQL估计没人用了。优化器会根据SQL语句以及当前表的实际数据情况等选择一个合适的执行方案，比如一条SQL查询语句有多个索引，优化器就要分析判断使用哪个索引查询代价更小，又比如如果表里的数据量很小的时候，全表扫描代价可能更小，优化器可能会选择全表扫描而不选择使用索引。 回顾一下我们经常使用的explain命令，在select前面加上explain关键字就可以知道本次查询执行计划。 查询语句一 mysql\u003e explain select * from `like` where id=1; +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | like | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL | +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.04 sec) mysql\u003e 查询语句二 mysql\u003e explain select * from `like` limit 1; +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ | 1 | SIMPLE | like | NULL | index | NULL | uk_user_id_liker_id | 8 | NULL | 3 | 100.00 | Using index | +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.03 sec) mysql\u003e 可以看到两次查询key这一列都不为空，查询语句一MySQL选择了PRIMARY主键索引，查询语句二则选择使用了uk_user_id_liker_id唯一索引，如果key为空，则代表没有使用索引，而是使用了全表扫描。 在实际开发中，一摸一样的SQL语句，在不同时刻执行执行计划可能会不一样，执行计划取决于很多因素，包括索引、表数据量大小等。总而言之MySQL会根据很多条件选择一种相对最优的执行计划减少SQL语句执行成本。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:5","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"执行器 经过前面的\"前戏\"后，终于要进入正题了，正式执行SQL语句了，执行器说白了就是MySQL的Server层和存储引擎层的一个桥梁，执行器并不实际执行SQL语句，而是通过API接口把经过一系列处理后的\"SQL语句\"丢给存储引擎执行，等待存储引擎返回执行结果，再把执行结果返回给查询缓存以及连接器。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:6","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"小结 总结一条SQL语句从客户端发起到客户端收到执行结果的过程 客户端经过连接器和MySQL服务端建立连接，连接器会校验用户名及密码是否正确，以及确定用户的权限，并存储用户的权限在内存中，在本次连接的生命周期中，用户的权限是一致的。 建立连接之后，请求来到了解析器，解析器主要干两件事：校验SQL语句是否符合语法规范，有语法错误直接报错；提取 SQL语句的关键字、表名、表字段关键信息。 经过解析器校验语法和提取关键信息后，请求到了预处理器，预处理器主要是确认SQL语句的表名字段名是否存在如果不存在直接报错，以及将 *关键字替换成实际的表字段。 经过上述检查和处理，就表示这条SQL语句是可执行的，但是在执行之前，服务端需要分析判断索引、当前数据表数据情况优化SQL语句执行，选择一个相对最优的方式去执行。 执行器收到优化器优化后的SQL语句，将SQL语句丢给存储引擎，然后等待执行结果将结果返回给执行器和查询缓存。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:1:7","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"索引 上述详细阐述了一条SQL语句从客户端到执行器丢给存储引擎整个流程，以上都是在MySQL的服务层实现的与存储引擎无关。本节主要介绍InnoDB存储引擎的索引概念和底层实现以及具体应用。 说到索引，首先要明确一下在MySQL中有哪些索引，根据不同维度划分，有以下几类索引 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:2:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"数据结构划分 索引类型\\存储引擎 InnoDB MyISAM Memory B+Tree Yes Yes Yes HASH No,会有自适应hash，存储引擎自动实现，没法指定。 No Yes Full-Text Yes Yes No InnoDB是MySQL默认的存储引擎，实际业务开发中，也比较推荐使用InnoDB，InnoDB事实上成了默认标准了 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:2:1","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"物理存储划分 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:2:2","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"字段特征划分 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:2:3","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"字段个数划分 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:2:4","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"三大日志 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:3:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"undo日志 undo日志是innodb引擎实现的一个 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:3:1","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"redo日志 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:3:2","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"bin日志 bin日志是mysql服务层实现的用于数据持久化的一种日志 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:3:3","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"各种锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"表级锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:1","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"行锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:2","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"间隙锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:3","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"临键锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:4","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"插入意向锁 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:5","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"自增锁 自增锁（Auto-Increment Lock）主要用于生成自增主键ID。在InnoDB中，当一张表的主键列设置为自增（AUTO_INCREMENT）时，每次插入新记录时，主键列的值会自动递增。自增锁确保在同一时间只有一个事务能够获取自增列的下一个值，避免在高并发场景下出现主键ID重复的问题。 当一个事务需要插入一条新记录时，它会请求自增锁，获取自增列的下一个值作为主键ID。在事务完成插入操作并释放自增锁之前，其他试图插入新记录的事务需要等待。这样，自增锁可以确保主键ID的唯一性，避免数据不一致的问题。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:4:6","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"事务 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:5:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"原子性 底层实现 一组操作要么都成功要么都失败，称之为原子性。设想一个场景，我现在有一个多写逻辑，有A、B、C三个步骤，A和B都成功了，C失败了，这个时候需要回滚数据恢复到这个逻辑之前，也就是要撤销A和B，这就要求我们需要知道被A和B修改成功的数据被修改之前的原始数据，然后用这个原始数据回滚，所以需要有一个地方记录被修改之前的原始数据。在Innodb中，这个存储被修改数据在修改之前的数据就是undo日志，也就是说，innodb的事务原子性是通过undo日志实现的。具体过程如下： Undo日志实现原子性 修改一行或多行数据，会在这个事务的update undo log链表中插入修改之前的数据，使用头插法按照修改的顺序插入数据，这些数据是按照修改的顺序逆序存储的，也就是说，最后修改的数据会被放在链表的最前面。 插入/删除一行或多行数据，会在这个事务的insert undo log链表中记录被插入/删除数据的主键id，使用头插法按照修改的顺序插入主键ID，这些ID也是按照插入的顺序逆序存储的，也就是说，最后插入的数据的ID会被放在链表的最前面。 如果事务执行失败或者被回滚，InnoDB会遍历上述日志链表，按照顺序执行回滚操作，以此来撤销事务中的所有修改。 小结 innodb借助undo日志实现事务的原子性，具体做法的在每次更新或者插入/删除数据之前先备份一下当前数据到undo日志链表中，当事务回滚的时候就可以遍历执行unlo日志链表达到回滚数据的目的 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:5:1","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"持久性 底层实现 持久性要求在数据库发生崩溃（如宕机、拔电源的时候，数据也能够保证不丢失。确保数据库从宕机等状态恢复的时候能够从磁盘中恢复尚未写到binlog的日志。和unro日志记录修改之前的数据不一样，redo日志是记录被修改后的数据，当数据库发生崩溃重启的时候，会根据unlo日志回滚尚未提交成功的事务。然后根据redo日志重放事务。 假设现在有两个事务，A事务执行到一半，B事务执行完成并提交，系统崩溃宕机，系统重启后，redo日志重放B事务并提交，undo日志回滚A事务。这就是InnoDB如何使用Undo日志和Redo日志来恢复系统状态的。通过这两种日志，InnoDB可以确保在系统崩溃后，所有已提交的事务的修改都不会丢失，所有未提交的事务的修改都可以被撤销，从而保证了数据库的一致性和持久性。 每次当一个事务进行修改操作时，InnoDB会生成相应的Redo日志，这个Redo日志有一个LSN，这是一个递增的数字，用来标识每个Redo日志的唯一性。同时，每个数据页在内存中也有一个LSN，表示这个数据页到哪个点被修改过。当这个Redo日志被应用到数据页时，也就是数据页被修改时，数据页的LSN会被更新为这个Redo日志的LSN。这样，数据页的LSN就表示了这个数据页被修改的最后一次操作。在重放过程中，InnoDB会比较Redo日志的LSN和数据页的LSN，只有当Redo日志的LSN大于数据页的LSN时，才会重放这个日志，也就是说，只有当Redo日志中的修改还没有被应用到数据页时，才会重放这个日志，所以在回放的时候并不是无脑回放所有的redo日志，而是会判断lsn丢弃掉已经持久化数据到数据页的redo日志，避免数据重复写入到数据页。mysql使用两阶段提交保证redo log和bin log的一致性，简单来说才数据写入bin log的时候会先写redo 日志，此时redo日志的状态为prepare，写redo日志成功后继续写bin log，bin log写成功后最后再把redo log的状态从prepare 改为commit。两阶段提交的目的是为了保证主库和从库数据的一致性，在事务崩溃的时候借助redo日志，可以恢复本机的数据页的数据，但是主从同步是借助bin log完成的，如果没有两阶段提交，可能会导致主库和从库的数据不一致。 两阶段提交保证binlog数据和本机数据一致性 小结 持久性依赖于undo和redo日志，每次事务提交的时候就会把redo日志落盘，当系统崩溃恢复的时候，会进入redo阶段回放日志，redo阶段的目的是为了将成功提交但还没持久化到数据页的那部分事务进行回放恢复；redo回放完成后进入到undo阶段，undo阶段的目的是将因系统崩溃导致未提交的事务的数据进行回滚避免脏数据。在redo阶段和undo阶段期间会阻塞所有写请求直到重放和恢复完成，这是为了确保数据库在恢复过程中保持一致性，避免在恢复过程中产生新的错误或不一致；而对于读请求则视事务的隔离级别以及数据库系统的配置而定。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:5:2","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"隔离性 在mysql中有四种隔离级别，按照隔离程度分别是读未提交、读已提交、可重复读、串行化。所谓隔离性指的是多事务之间是隔离的，互相不干扰，抛开事务来看，我们日常写业务代码的时候，涉及到对多个线程共享的数据进行读写的时候，为了保证数据的安全性，一般会对共享数据进行加锁，其实这个“加锁”就是mysql中的最高隔离级别串行化。在mysql中为了兼顾性能和数据一致性，提供了不同的隔离级别，业务可以根据自己实际使用情况选用不同的隔离级别。 读未提交 最低的一种隔离级别，在事务中读到的数据永远是当前数据库最新的数据，在一个事务执行过程中，如果有其它事务对该事务读取的数据进行修改，可以读到其它事务修改但还未提交的数据。可以把它类比于多线程对共享数据进行读写，但不做任何并发保护，可能会导致读到很奇怪的数据，甚至读到修改一半的数据。读未提交因为是最低的隔离级别，性能自然也是最好的，因为不需要任何手段保护数据，但是数据一致性也是最差的。读未提交可能会导致脏读(读到其它事务更新但又回滚的数据)、不可重复读（多次读同一条数据结果不一样）幻读（多次读同一个范围内的数据返回的结果少了或者多了数据）。读未提交适用于对性能要求比较高，但是对于数据一致性要求稍弱的场景，比如实时数据分析、缓存预热、非关键业务数据查询 读已提交 可以读到其它事务提交的数据，底层使用mvcc+redo实现，每次查询的时候都会开启一个快照，获取当前还没提交的事务ID列表，下一个事务ID是上述列表中最大事务ID+1，判断读到的数据的的事务ID是否在这个还未提交的事务ID列表中以及是否是下一个事务ID，如果不在的话，就认为数据是可信的，直接返回，否则的话会沿着回滚链表指针向后遍历直到找到可信的数据。因为每次查询都会开启一个快照，所以如果第一次快照里面的某些事务在第二次开启快照的时候提交了，第二次开启快照的时候未提交事务ID列表就没有第一次和第二次快照这个时间区间内的事务（因为已经提交了），所以会读到本事务执行期间其它已经成功提交的事务的数据，所以会造成不可重复读。在读已提交这个隔离级别，只有行锁和表锁起作用。 可重复读 实现和读已提交类似，区别在于rr隔离级别会在事务启动的时候开启一个全局快照，而不是像读已提交每次都会开启一个快照，也就是说rr级别下，整个事务周期中其它未提交事务ID列表和下一个事务ID是保持不变的，这样的好处在于其它事务提交的数据跟我无关，在快照读的情况下可以避免不可重复读和幻读的问题。但是需要注意的是，对于当前读（如 select .. for update /update /delete等语句）会读到当前的最新数据，对于当前读，rr会使用next-key lock+行锁来尽量保证避免出现幻读的问题，但是不能百分之百保证幻读，典型的如下两个例子。⚠️：幻读在rr隔离级别下只会出现在当前读这个场景，对于普通读是没有影响的。 case1 begin select name from user where id=2; # user表中不存在id=2这条数据，读出来是空 #....在这个区间内另一个事务执行 insert into user (id,name) values(2,\"lisi\")并成功提交 update user set name='zhangsan' where id=2; # 因为此时user表中有id=2这条数据，update会当前读，所以这条数据成功更新了 select name from user where id=2; # user表中存在id=2这条数据，并且是由本事务更新的，所以读出来这条数据是 `zhangsan` commit # 在以上事务执行过程中，出现一模一样的sql执行语句两次执行结果不一样，出现了幻读，由于update是当前读会更新表中的数据，第二次读的时候发现表中隐藏列的指针代表的版本是本事务修改的，所以认为数据是可信的，返回结果。 case2 begin select * from user where id\u003e3; # 此时有表中有三条数据 id 分别为4、5、6 #....在这个区间内另一个事务执行 insert into user (id,name) values(7,\"lisi\")并成功提交 select * from user where id\u003e3 for update; # 因为for update 是当前读，并且由于第一次读是快照读不回上写锁，所以本次读会读出四条数据，id 分别为 4、5、6、7 commit # 两次读的数据不一样，出现了幻读，原因在于第一个select语句是快照读只会加读锁不回加写锁，也就是说阻止不了其他事务插入删除或者更新数据，而刚好第二次读是当前读，读到的最新的数据，导致了两次读取数据不一样。但是如果把两个语句换个顺序就不会出现幻读的问题了，因为for update会加next-key lock(gap 锁+行锁)，会锁住数据其他事务在本事务提交之前是不能进行增、删、改的操作 begin select * from user where id\u003e3 for update; # 此时有表中有三条数据 id 分别为4、5、6，会加间隙锁[4,+∞),直到本事务提交才释放 select * from user where id\u003e3; # 因为第一次select加锁了，所以本次读出来的数据和第一次一样，不会出现幻读。 commit 串行化 最高的一种隔离级别，类似于加读写锁，同一时刻只有一个事务在执行，类似于单线程的方式。这种隔离级别下不回出现以上三种隔离级别的问题，但是性能也是最差的。一般用在对于数据一致性要求极高的场景，如银行、金融等领域。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:5:3","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"一致性 上述疏导的原子性、隔离性、持久性，都是手段，一致性才是目的，换句话说mysq实现了原子性、持久性、隔离性保证数据的一致性。 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:5:4","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"数据结构 ","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:6:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"内存","date":"2023-07-01","objectID":"https://www.bardblog.cn/mysql-core-concepts/:7:0","tags":["MySQL","InnoDB"],"title":"MySQL核心概念","uri":"https://www.bardblog.cn/mysql-core-concepts/"},{"categories":["technology"],"content":"对于reactor的一点理解","date":"2023-07-01","objectID":"https://www.bardblog.cn/reactor-pattern/","tags":["IO","Reactor","Redis","Kafka"],"title":"Reactor模式","uri":"https://www.bardblog.cn/reactor-pattern/"},{"categories":["technology"],"content":"介绍git的一些不太常见的高级用法","date":"2023-06-27","objectID":"https://www.bardblog.cn/git-advanced-usage/","tags":["git","linux"],"title":"Git高级用法","uri":"https://www.bardblog.cn/git-advanced-usage/"},{"categories":["technology"],"content":"Git 子模块 ","date":"2023-06-27","objectID":"https://www.bardblog.cn/git-advanced-usage/:1:0","tags":["git","linux"],"title":"Git高级用法","uri":"https://www.bardblog.cn/git-advanced-usage/"},{"categories":["technology"],"content":"概念 Git 子模块允许你将另一个 Git 仓库作为主仓库的子目录引入。每个子模块都是一个独立的 Git 项目，具有自己的提交、拉取和推送操作。主仓库以子模块的形式包含多个子仓库。 ","date":"2023-06-27","objectID":"https://www.bardblog.cn/git-advanced-usage/:1:1","tags":["git","linux"],"title":"Git高级用法","uri":"https://www.bardblog.cn/git-advanced-usage/"},{"categories":["technology"],"content":"示例 我们通过一个示例来了解如何使用 Git 子模块。 创建一个名为 “gitSubmodules” 的文件夹，并将其初始化为 Git 仓库： mkdir gitSubmodules cd gitSubmodules git init 添加一个远程 origin，并将仓库推送到 GitHub： git remote add origin git@github.com:你的用户名/gitSubmodules.git echo \"关于 gitSubmodules\" \u003e\u003e README.md git add . git commit -m \"初始化 gitSubmodules\" git push --set-upstream origin main 在这里，将 “你的用户名” 替换为你的 GitHub 用户名。 现在，让我们将两个子仓库添加到 “gitSubmodules” 仓库中： git submodule add git@github.com:你的用户名/submodule1.git git submodule add git@github.com:你的用户名/submodule2.git 执行这些命令后，“gitSubmodules” 仓库将添加子模块 “submodule1” 和 “submodule2”。此命令会将子模块的远程仓库克隆到 “gitSubmodules” 仓库的根目录中。 默认情况下，每个子模块将被放置在与子仓库同名的目录中。 如果你执行 git status 命令，你将看到仓库中现在有一个名为 “.gitmodules” 的文件，以及两个名为 “submodule1” 和 “submodule2” 的目录。 “.gitmodules” 文件存储了子模块的本地目录路径与远程仓库 URL 之间的映射关系。 提交并推送更改到主仓库： git add . git commit -m \"添加 submodule1 和 submodule2 子模块\" git push 这将把子模块的信息一并推送到远程仓库。 如果有人克隆了 “gitSubmodules” 仓库，他们最初会得到子模块的空目录。为了将子模块填充为其相应的内容，他们需要运行以下命令： git submodule init git submodule update 运行这些命令后，子模块的远程文件将与本地仓库同步，包括每个子模块的提交信息。 ","date":"2023-06-27","objectID":"https://www.bardblog.cn/git-advanced-usage/:1:2","tags":["git","linux"],"title":"Git高级用法","uri":"https://www.bardblog.cn/git-advanced-usage/"},{"categories":["technology"],"content":"使用场景 Git 子模块在需要在主项目中引入其他项目时非常有用,每个项目可以拥有自己独立的仓库和版本控制历史，确保对主项目和子模块的修改互不干扰。 ","date":"2023-06-27","objectID":"https://www.bardblog.cn/git-advanced-usage/:1:3","tags":["git","linux"],"title":"Git高级用法","uri":"https://www.bardblog.cn/git-advanced-usage/"},{"categories":null,"content":"About Bard","date":"2023-06-24","objectID":"https://www.bardblog.cn/about/","tags":null,"title":"About Bard","uri":"https://www.bardblog.cn/about/"},{"categories":null,"content":"英文名：BardChen 地点：北京 职业：程序员 运动：跑步、羽毛球、爬山 博客源码：https://github.com/YourFantasy/blog 博客理念：记录生活、记录成长。 2024愿望：遇到一个真诚善良的人，谈一段有结果的恋爱。 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/about/:0:0","tags":null,"title":"About Bard","uri":"https://www.bardblog.cn/about/"}]