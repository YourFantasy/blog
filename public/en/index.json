[{"categories":["heartbeat"],"content":"阳光明媚，温暖人心的小太阳。","date":"2024-01-20","objectID":"https://www.bardblog.cn/en/my-love/","tags":["gentle","sunlight"],"title":"我的小太阳","uri":"https://www.bardblog.cn/en/my-love/"},{"categories":["technology"],"content":"Three types of factory patterns","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"The Factory Method pattern is a creational design pattern that provides a way to delegate the creation of objects to subclasses. In the Factory Method pattern, an abstract factory class defines an interface for creating objects, but the specific object creation is deferred to the subclasses. ","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/:0:0","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"Simple Factory Pattern The Simple Factory pattern, also known as the Static Method pattern, defines a static method in the object creation factory class to create objects. The Simple Factory design pattern allows clients (users) to create the desired product instances without knowing the specific details of the objects. Users can directly use the created objects without worrying about how they are created. Class Diagram: Simple Factory Pattern Code: package main import \"fmt\" type Animal interface { eat() weight() int } type Dog struct { } func (d *Dog) eat() { fmt.Println(\"dog eat !\") } func (d *Dog) weight() int { return 30 } type Cat struct { } func (c *Cat) eat() { fmt.Println(\"cat eat!\") } func (c *Cat) weight() int { return 10 } type AnimalFactory struct { } func (a *AnimalFactory) newAnimal(animalType int) Animal { switch animalType { case 0: return \u0026Dog{} case 1: return \u0026Cat{} default: return nil } } func main() { factory := new(AnimalFactory) dog := factory.newAnimal(0) dog.eat() fmt.Println(dog.weight()) cat := factory.newAnimal(1) cat.eat() fmt.Println(cat.weight()) } As you can see, the Simple Factory pattern is quite simple. It separates the creation and usage of instances, allowing the users to create objects without knowing the details of the objects’ creation process. It achieves separation and decoupling, where users only need to know the type mapping of the objects they want to create. However, what are the drawbacks of the Simple Factory pattern? When producing objects, the specific animal object to be created is determined based on the animal type passed in. As we add more animal types, such as rabbits or elephants, the newAnimal method will expand continuously. Moreover, whenever the animal types change, we have to modify this part of the code, which violates the Open-Closed Principle. So, how can we address this issue? We can’t really say that it solves the problem completely, but it can be considered as a programming technique. We can observe that the newAnimal method contains a lot of switch cases. How can we get rid of these switch cases? In the main function, when we need to create a specific animal object, we need to pass the animalType field and then call the newAnimal method to create the object. In other words, we create the object only when we need to use a certain animal object, which follows a “lazy loading” approach. If we create an instance of each animal whenever we add a new animal, and then put it into a map dictionary, we can simply fetch the object from the map without maintaining the newAnimal method. In essence, it transforms the “lazy loading” approach into an “eager loading” approach. Regardless of whether you use the object or not, if the object exists, we create an object instance and put it into the map dictionary. The code can be modified as follows: Code: package main import \"fmt\" // Eager loading, register into the factory map func init() { Register(0, \u0026Dog{}) Register(1, \u0026Cat{}) } type Animal interface { eat() weight() int } type Dog struct { } func (d *Dog) eat() { fmt.Println(\"dog eat !\") } func (d *Dog) weight() int { return 30 } type Cat struct { } func (c *Cat) eat() { fmt.Println(\"cat eat!\") } func (c *Cat) weight() int { return 10 } type AnimalFactory struct { } func Register(animalType int, animal Animal) { animals[animalType] = animal } func Get(animalType int) Animal { a, ok := animals[animalType] if !ok { return nil } return a } var animals = make(map[int]Animal) // animal type =\u003e Animal func main() { dog := Get(0) dog.eat() fmt.Println(dog.weight()) cat := Get(1) cat.eat() fmt.Println(cat.weight()) } ","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/:1:0","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"Factory Method Pattern The Factory Method pattern, also known as the Polymorphic Factory pattern, is an upgraded version of the Simple Factory pattern. In the previous explanation, we discussed the Simple Factory pattern, where different types of animals, such as dogs and cats, were produced by the same animal factory. However, every time a new animal species is added, the animal factory needs to be modified accordingly. It’s like needing to add matching tools every time a new animal species is produced, which is not very scalable. The Factory Method pattern can be seen as an improvement to the Simple Factory pattern, where different types of animals are no longer produced by the same animal factory. Instead, the production is further divided, and each type of animal has its own dedicated animal factory. Let’s take the example of cars. Class Diagram: Factory Method Pattern Code: package main import \"fmt\" // Car abstract interface for cars, defining two behaviors: drive and refuel type Car interface { drive() refuel(cnt int) } // Bmw BMW car type Bmw struct { } func (b *Bmw) drive() { fmt.Println(\"I'm driving a BMW!\") } func (b *Bmw) refuel(cnt int) { fmt.Println(\"Adding\", cnt, \"liters of fuel to the BMW\") } // Benz Benz car type Benz struct { } func (b *Benz) drive() { fmt.Println(\"I'm driving a Benz!\") } func (b *Benz) refuel(cnt int) { fmt.Println(\"Adding\", cnt, \"liters of fuel to the Benz\") } // CarFactory interface for car factories, responsible for car production type CarFactory interface { makeCar() Car } // BmwFactory BMW car factory, producing BMW cars type BmwFactory struct { } func (b *BmwFactory) makeCar() Car { return new(Bmw) } // BenzFactory Benz car factory, producing Benz cars type BenzFactory struct { } func (b *BenzFactory) makeCar() Car { return new(Benz) } func main() { bmwFactory := new(BmwFactory) bmw := bmwFactory.makeCar() bmw.drive() bmw.refuel(1) benzFactory := new(BenzFactory) benz := benzFactory.makeCar() benz.drive() benz.refuel(2) } In summary, let’s highlight the advantages and disadvantages of the Factory Method pattern: Advantages: Good scalability: When a new product (e.g., adding an Audi car) needs to be added, there is no need to modify the abstract factory or the interface provided by the abstract factory. Only a specific factory and product need to be added. This approach aligns with the “Open-Closed Principle.” In contrast, the Simple Factory pattern requires modification of the factory class’s conditional logic. Adheres to the Single Responsibility Principle: Each specific factory class is only responsible for producing the corresponding product. The Simple Factory pattern’s factory class requires additional logical checks. The key to the Factory Method pattern lies in the polymorphism design based on the factory and product roles. It allows the factory to independently determine which product object to create (the product’s factory class only needs to implement the abstract factory interface). The details of how to create the object are completely encapsulated within the specific factory. The Factory Method pattern is also referred to as the “Polymorphic Factory” pattern because all specific factory classes have the same abstract parent class. Disadvantages: Every time a new product is added, new concrete product classes need to be written, along with providing the corresponding factory classes,When the number of products in the system becomes large, the number of classes increases exponentially, resulting in increased system complexity. Additionally, multiple classes need to be compiled and executed, which adds to the system’s overhead. A specific factory class can only create one specific product. ","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/:2:0","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"Abstract Factory Pattern The Abstract Factory pattern can be understood as a factory of factories, where there is a super factory that produces other factories. As Marx said, “Man is the sum of all social relations.” A person cannot play only one role in society. A person’s occupation could be a programmer, and they also have corresponding family roles. Likewise, a programmer could specialize in languages such as Go, Java, or Python, and their family roles could be a father, son, or husband. Together, these roles constitute the sum of social relations. The Abstract Factory pattern can be seen as a combination of the Simple Factory pattern and the Factory Method pattern. It inherits their respective advantages and disadvantages. Class Diagram: Abstract Factory Pattern Code: package main import \"fmt\" type programmer interface { writeCode() } type javaProgrammer struct { } func (j *javaProgrammer) writeCode() { fmt.Println(\"I am a Java programmer. I write Java.\") } type goProgrammer struct { } func (g *goProgrammer) writeCode() { fmt.Println(\"I am a Golang programmer. I write Go.\") } type family interface { love() } type father struct { } func (f *father) love() { fmt.Println(\"I am a father. I love my wife and my son.\") } type son struct { } func (s *son) love() { fmt.Println(\"I am a son. I love my father and my mother.\") } type programmerFactory struct { } func (p *programmerFactory) getProgrammer(programmerType int) programmer { switch programmerType { case 0: return new(javaProgrammer) case 1: return new(goProgrammer) default: return nil } } func (p *programmerFactory) getFamily(roleType int) family { return nil } type familyFactory struct { } func (f *familyFactory) getFamily(roleType int) family { switch roleType { case 0: return new(father) case 1: return new(son) default: return nil } } func (f *familyFactory) getProgrammer(programmerType int) programmer { return nil } type abstractHumanFactory interface { getFamily(roleType int) family getProgrammer(programmerType int) programmer } type factoryProducer struct { } func (*factoryProducer) getFactory(factoryType int) abstractHumanFactory { switch factoryType { case 0: return new(programmerFactory) case 1: return new(familyFactory) default: return nil } } func main() { fac := new(factoryProducer) programmerFac := fac.getFactory(0) java := programmerFac.getProgrammer(0) java.writeCode() golang := programmerFac.getProgrammer(1) golang.writeCode() familyFac := fac.getFactory(1) f := familyFac.getFamily(0) f.love() s := familyFac.getFamily(1) s.love() } ","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/:3:0","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"Summary The Factory pattern is the simplest and most easily understandable design pattern, and it is widely used in daily development. It can be roughly divided into three types. Correctly using design patterns in our code can greatly simplify the code, reduce code coupling, and improve maintainability (after all, it is a summary of previous experiences). However, it is essential to avoid the misuse of design patterns. Improper use can have adverse effects. Don’t use design patterns just for the sake of using them! ","date":"2023-06-26","objectID":"https://www.bardblog.cn/en/desigin-pattern-factory/:4:0","tags":["design-pattern"],"title":"Factory Pattern","uri":"https://www.bardblog.cn/en/desigin-pattern-factory/"},{"categories":["technology"],"content":"Solving connected components problem using Depth-First Search","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"Problem Description Given an n×m 2D integer array representing a maze, where the array contains only 0s and 1s, with 0 representing a path that can be traversed and 1 representing an impassable wall. Initially, there is a person at the top-left corner (1, 1). It is known that the person can move one position in any direction: up, down, left, or right. The task is to determine the minimum number of moves required for the person to reach the bottom-right corner (n, m). It is guaranteed that the numbers at the top-left corner (1, 1) and the bottom-right corner (n, m) are both 0, and there is at least one valid path. Input Format The first line contains two integers, n and m. The next n lines contain m integers (0 or 1), representing the complete 2D array maze. Output Format Print a single integer, representing the minimum number of moves required to reach the bottom-right corner from the top-left corner. Constraints 1 ≤ n, m ≤ 100 Input Example: 5 5 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 Output Example: 8 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/:1:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"Approach This is a typical shortest path problem. We can use breadth-first search (BFS) to traverse the path from the start to the end, while keeping track of the minimum number of moves. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/:2:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"Code Implementation package main import \"fmt\" const N = 101 func main() { var n, m int fmt.Scanf(\"%d%d\", \u0026n, \u0026m) nums := make([][]int, n) d := make([][]int, n) for i := 0; i \u003c n; i++ { nums[i] = make([]int, m) d[i] = make([]int, m) for j := 0; j \u003c m; j++ { var tmp int fmt.Scanf(\"%d\", \u0026tmp) nums[i][j] = tmp d[i][j] = -1 } } fmt.Println(bfs(nums, d, newQueue(N*N))) } func bfs(nums, d [][]int, q *queue) int { n, m := len(nums), len(nums[0]) d[0][0] = 0 dx := [4]int{-1, 0, 1, 0} dy := [4]int{0, 1, 0, -1} q.push(\u0026pair{0, 0}) for !q.isEmpty() { t := q.pop() for i := 0; i \u003c 4; i++ { // Check four directions: up, down, left, right x, y := t.x+dx[i], t.y+dy[i] // Next position from the current position if x \u003e= 0 \u0026\u0026 x \u003c n \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c m \u0026\u0026 nums[x][y] == 0 \u0026\u0026 d[x][y] == -1 { d[x][y] = d[t.x][t.y] + 1 q.push(\u0026pair{x, y}) } } } return d[n-1][m-1] } type pair struct { x int y int } type queue struct { elements []*pair begin int end int } func newQueue(n int) *queue { return \u0026queue{ elements: make([]*pair, n), begin: 0, end: -1, } } func (q *queue) push(p *pair) { q.end += 1 q.elements[q.end] = p } func (q *queue) pop() *pair { res := q.elements[q.begin] q.elements[q.begin] = nil q.begin += 1 return res } func (q *queue) isEmpty() bool { return q.end \u003c q.begin } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/:3:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-bfs-acwing-844/"},{"categories":["technology"],"content":"Solving connected components problem using Depth-First Search","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Problem Description Given a tree with n nodes (numbered 1 to n) and n-1 undirected edges. Please find the centroid of the tree and output the maximum number of nodes in each remaining connected component after removing the centroid. Centroid Definition: The centroid of a tree is a node such that if it is removed, the maximum number of nodes in each remaining connected component is minimized. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:1:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Input Format The first line contains an integer n, representing the number of nodes in the tree. The next n-1 lines contain two integers a and b each, representing an edge between nodes a and b. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:2:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Output Format Output an integer m, representing the maximum number of nodes in each remaining connected component after removing the centroid. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:3:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Constraints 1 ≤ n ≤ 105 Sample Input: 9 1 2 1 7 1 4 2 8 2 5 4 3 3 9 4 6 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:4:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Approach ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:5:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Code Implementation ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:6:0","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Code 1 package main import ( \"bufio\" \"fmt\" \"os\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) son := make(map[int]*listNode) used := make([]bool, n+1) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 2000*1000) scanner.Buffer(buf, len(buf)) for i := 0; i \u003c n-1; i++ { scanner.Scan() ss := strings.Split(scanner.Text(), \" \") var a, b int a, _ = strconv.Atoi(ss[0]) b, _ = strconv.Atoi(ss[1]) add1(son, used, a, b) } res := n dfs1(son, n, 1, \u0026res, make([]bool, n+1)) fmt.Println(res) } func dfs1(mp map[int]*listNode, n, t int, res *int, visited []bool) int { visited[t] = true tmp := 0 sum := 1 for h := mp[t]; h != nil; h = h.next { if !visited[h.val] { s := dfs1(mp, n, h.val, res, visited) tmp = max(tmp, s) sum += s } } tmp = max(tmp, n-sum) *res = min(*res, tmp) return sum } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } // add1 constructs the graph // son: stores the child nodes for each node with key k // used: tracks whether node b has been used as a child node of any node // Since a node can only be a child node of one node, if node b was a child node before, then at this moment, node b is the parent node of node a, and node a is the child node of node b func add1(son map[int]*listNode, used []bool, a, b int) { if !used[b] { newNode := \u0026listNode{val: b, next: son[a]} son[a] = newNode used[b] = true } else { newNode := \u0026listNode {val: a, next: son[b]} son[b] = newNode } } type listNode struct { val int next *listNode } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:6:1","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Code 2 package main import ( \"bufio\" \"fmt\" \"os\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) h, c, ne := make([]int, n+1), make([]int, 2*n+1), make([]int, 2*n+1) for i := 0; i \u003c= n; i++ { h[i] = -1 } idx := 0 visited := make([]bool, n+1) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 20000*1000) scanner.Buffer(buf, len(buf)) for i := 0; i \u003c n-1; i++ { scanner.Scan() s := scanner.Text() ss := strings.Split(s, \" \") var a, b int a, _ = strconv.Atoi(ss[0]) b, _ = strconv.Atoi(ss[1]) add2(h, c, ne, a, b, \u0026idx) add2(h, c, ne, b, a, \u0026idx) } res := n dfs2(h, c, ne, n, 1, visited, \u0026res) fmt.Println(res) } func dfs2(h, c, ne []int, n, t int, visited []bool, res *int) int { visited[t] = true sum := 1 tmp := 0 for i := h[t]; i != -1; i = ne[i] { if !visited[c[i]] { s := dfs2(h, c, ne, n, c[i], visited, res) sum += s tmp = max(tmp, s) } } tmp = max(tmp, n-sum) *res = min(*res, tmp) return sum } // Build the connection graph // Reference: https://www.acwing.com/file_system/file/content/whole/index/content/4446359/ func add2(h, c, ne []int, p, s int, idx *int) { c[*idx] = s ne[*idx] = h[p] h[p] = *idx *idx += 1 } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/:6:2","tags":["algorithm","bfs"],"title":"Maximum Size of Connected Components","uri":"https://www.bardblog.cn/en/algorithm-dfs-acwing-846/"},{"categories":["technology"],"content":"Solving interval merging problem using Greedy algorithm","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/","tags":["algorithm","greed"],"title":"Maximum Non-overlapping Intervals","uri":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"Problem Description Given N closed intervals [ai, bi], you need to select a subset of intervals on the number line such that the selected intervals do not overlap with each other (including the endpoints). Output the maximum number of intervals that can be selected. Input Format The first line contains an integer N, representing the number of intervals. The next N lines contain two integers ai and bi each, representing the endpoints of an interval. Output Format Output an integer representing the maximum number of non-overlapping intervals that can be selected. Constraints 1 ≤ N ≤ 105, -109 ≤ ai ≤ bi ≤ 109 Sample Input: 3 -1 1 2 4 3 5 Sample Output: 2 ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/:1:0","tags":["algorithm","greed"],"title":"Maximum Non-overlapping Intervals","uri":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"Code Implementation package main import ( \"bufio\" \"fmt\" \"os\" \"sort\" \"strconv\" \"strings\" ) func main() { var n int fmt.Scanf(\"%d\", \u0026n) scanner := bufio.NewScanner(os.Stdin) buf := make([]byte, 2000*1024) scanner.Buffer(buf, len(buf)) points := make([][]int, n) for i := 0; i \u003c n; i++ { scanner.Scan() strList := strings.Split(scanner.Text(), \" \") a, _ := strconv.Atoi(strList[0]) b, _ := strconv.Atoi(strList[1]) points[i] = []int{a, b} } sort.Slice(points, func(i, j int) bool { return points[i][1] \u003c points[j][1] }) cnt := 1 rightPoint := points[0][1] for i := 1; i \u003c n; i++ { if points[i][0] \u003e rightPoint { cnt++ rightPoint = points[i][1] } } fmt.Println(cnt) } ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/:2:0","tags":["algorithm","greed"],"title":"Maximum Non-overlapping Intervals","uri":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"Proof First, sort the original intervals in ascending order of their right endpoints. For the first interval, select its right endpoint. Starting from the second interval, check if there is an intersection between the current interval and the previous intervals. If there is an intersection, merge the two intervals (rightPoint is the minimum right endpoint before merging); otherwise, increment the count of non-overlapping intervals. For the k-th interval, if the current interval does not intersect with any of the previous intervals (if the left endpoint of the current interval is greater than the minimum right endpoint of the previous intervals), increment the count of non-overlapping intervals by 1. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/:3:0","tags":["algorithm","greed"],"title":"Maximum Non-overlapping Intervals","uri":"https://www.bardblog.cn/en/algorithm-greedy-disjoint/"},{"categories":["technology"],"content":"Introduction to the core concepts of MySQL","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/interview/","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/interview/"},{"categories":["technology"],"content":"Introduction to the core concepts of MySQL","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"MySQL Introduction to the core concepts of MySQL and their underlying implementation, all based on the MySQL InnoDB storage engine. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:0:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"SQL Statement Execution Process When we start learning SQL, the first thing we usually learn is the select statement. Here’s a simple query: // Retrieve a record with id=1 from the student table select * from student where id=1; What is the complete process involved in executing this SQL statement? “What does MySQL do internally when executing this simple SQL statement?” With these questions in mind, let’s dive into MySQL and explore its internal architecture. Let’s start by looking at the execution process of an SQL statement from a global perspective. The diagram below illustrates the entire flow of a SQL statement, from the client to the data storage, including the modules within the MySQL architecture. MySQL Execution Flow We can see that MySQL is divided into two layers: the Server layer and the storage engine layer. The Server layer is responsible for establishing client connections, analyzing, optimizing, and executing SQL statements. The Server layer is independent of the storage engine. It encompasses the core modules of MySQL, including the connector, parser, preprocessor, optimizer, and executor. Additionally, MySQL’s built-in functions and all cross-storage engine features are implemented in the Server layer. The storage engine layer is responsible for data retrieval and storage. There are multiple storage engines available, with InnoDB, MyISAM, and Memory being common ones. These engines provide the same interface to the Server layer but have different specific implementations. In this article, we will mainly focus on the InnoDB storage engine, which is also the default storage engine in MySQL. Familiar concepts in MySQL, such as indexes, transactions, and locks, are implemented at the storage engine layer. InnoDB uses B+ tree indexes, and primary key indexes, composite indexes, and regular indexes created in database tables all use B+ tree indexes. The above description provides an overview of the overall architecture of MySQL, which can be considered “not too complex.” It consists of the Server layer and the storage engine layer. Let’s now delve into the specific details. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Connector If you want to perform CRUD operations on MySQL, the first step is to establish a connection with MySQL. Generally, the following command is used to establish a connection with the MySQL service: # -h specifies the hostname or IP address # -u specifies the username # -p specifies the password, for security reasons it is generally not hard-coded and is manually entered in the console after executing the command mysql -h ip -u user -p For example: mysql -h 192.168.1.111 -u root -p Since MySQL’s transport layer protocol is based on TCP, the process of establishing a connection requires the TCP three-way handshake. If the MySQL server is running properly, after establishing the TCP connection, it will verify if the username and password are correct. If the username or password is incorrect, an error will be reported: Access denied for user. If the username and password are correct, the connector will query the permissions associated with that user based on the username. It will save the permissions in memory, and until the connection is closed, even if the administrator modifies the user’s permissions, it will not affect the permissions for the current connection. The new permissions will be used only when the next connection is established. During the current connection’s lifecycle, all read and write operations for the user will be based on the permissions saved in memory during authentication. You can use the following command to view the current connections established with the MySQL server: mysql\u003e show processlist; +----------+------+--------------------+-------------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----------+------+--------------------+-------------+---------+------+-------+------------------+ | 10773010 | root | 10.99.17.131:21086 | NULL | Sleep | 210 | | NULL | | 10773094 | root | 10.99.17.131:23980 | mysql_learn | Sleep | 72 | | NULL | | 10773150 | root | 10.99.17.131:25924 | NULL | Query | 0 | init | show processlist | +----------+------+--------------------+-------------+---------+------+-------+------------------+ 3 rows in set (0.02 sec) You can see that three users with the username “root” have established connections with the MySQL service. Among them, the user with Id 10773010 has an empty database (db) and the value of Command is “Sleep”, indicating that the user has not executed any other commands after connecting and has been idle for 210 seconds (Time column). Does this idle time keep increasing indefinitely? In other words, does the MySQL connection stay open continuously? Certainly not. It is not possible for a connection to be established a year ago and for MySQL to keep it active while I haven’t done anything (just like making a reservation at a restaurant and if you don’t show up within a certain time, they will cancel it). MySQL also has a similar mechanism. If a connection remains idle for a long time without any activity, it will automatically be closed after a certain period of time. This maximum idle time is controlled by the wait_timeout parameter, which defaults to 2 * 60 * 60 = 7200 seconds. mysql\u003e show variables like 'wait_timeout'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | wait_timeout | 7200 | +---------------+-------+ 1 row in set (0.03 sec) If we find a connection undesirable, we can also manually kill that connection using the kill connection +Id command. If I want to kill the connection with Id 10773010, I simply execute the following command: mysql\u003e kill connection +10773010; Query OK, 0 rows affected (0.02 sec) mysql\u003e show processlist; +----------+------+--------------------+-------------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----------+------+--------------------+-------------+---------+------+-------+------------------+ | 10773094 | root | 10.99.17.131:23980 | mysql_learn | Sleep | 895 | | NULL | | 10773","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:1","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Query Cache After establishing a connection, the client can send SQL statements to the MySQL server for execution. Upon receiving an SQL statement, the MySQL server first determines whether it is a query statement (based on whether the first field of the SQL statement is “SELECT”). If it is a query statement, MySQL checks the query cache to see if there is a cached result for this SQL statement. If a cached result exists, it is directly returned to the client without further processing. The cache is stored in a key-value format, where the key is the SQL query statement and the value is the query result. While this caching mechanism seems promising, there are concerns regarding cache hit rates and efficiency. In general, MySQL’s query cache has a high invalidation rate because any data update in the MySQL table will invalidate the cache. For example, if we execute the following query: SELECT * FROM student WHERE id=1; After the first execution of this query, MySQL caches the result for id=1. However, if MySQL performs an update statement, the cache will be invalidated. For instance, if MySQL updates the data for id=2: UPDATE student SET name='张三' WHERE id=2; One might wonder why MySQL takes such a blunt approach. After all, updating id=2 should not affect the result for id=1. However, MySQL does not have knowledge of whether updating id=2 would impact the record for id=1, or the cost of determining the impact is too high (difficult to assess). To ensure data consistency, MySQL simply invalidates the cache whenever there is an update operation. From the analysis above, it appears that the query cache has limited utility. Even in scenarios where there are more reads than writes, complete avoidance of writes is not feasible. As long as there is a write operation, all caches for the table become invalidated, incurring significant costs. Therefore, starting from version 8.0, MySQL has removed the query cache feature. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:2","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Parser For an SQL statement to be executed successfully, it must first comply with the SQL syntax rules defined by MySQL. These rules can be understood as the mutually agreed-upon guidelines between us and MySQL. We adhere to these rules when writing SQL statements, and similarly, MySQL follows these rules to parse and execute the SQL statements we write. It is not feasible for us to provide MySQL with arbitrary strings and expect it to execute them. Before executing an SQL statement, MySQL needs to understand the purpose of the statement, whether it is an insert, delete, update, or select operation, as well as the tables and fields involved in the SQL statement. This information can be extracted based on the syntax rules, which is essentially the task of the parser. The parser performs two main tasks: Syntax Analysis: MySQL checks whether the SQL statement has any syntax errors based on the agreed-upon syntax rules. If there are syntax errors, MySQL will directly report an error, such as “You have an error in your SQL syntax”. For example, if we execute the following statement: mysql\u003e slect * from friend where id=1; ERROR 2013 (HY000): Lost connection to MySQL server during query No connection. Trying to reconnect... Connection id: 10788396 Current database: mysql_learn ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'slect * from friend where id=1' at line 1 mysql\u003e Here, we mistakenly typed slect instead of select. MySQL checks the SQL statement against the syntax rules and identifies that it does not conform to the syntax. As a result, it reports an error. This process is similar to the parameter validation commonly used in backend development. Lexical Analysis: Regardless of the complexity of an SQL statement, it always follows certain patterns. For example, the keyword where is always followed by a query condition, and the keyword from is followed by a table name. MySQL implements a lexical analyzer that extracts table names, SQL types, field names, and query conditions from the SQL statement. This preparation work is then passed on to the subsequent modules for further processing. It’s important to note that while syntax checking and lexical analysis are performed by the parser, the verification of table names and field names’ existence is not handled at the parser level. This can be understood as the parser layer being focused on local logic and not involving network or API calls. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:3","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Preprocessor Once an SQL statement is parsed, it can be determined that the statement is potentially executable. However, this doesn’t guarantee its successful execution. Parsing the SQL statement ensures that the syntax is correct and extracts key information such as table names, but it doesn’t verify if the SQL statement can be executed successfully. For example, if the SQL statement refers to a table that doesn’t exist, it won’t be executed successfully. The preprocessor performs two main tasks: Checking the Existence of Tables and Fields: The preprocessor checks whether the table names and field names extracted by the parser exist. This step involves reading table information and verifying the existence of table names and field names. If any of the referenced tables or fields don’t exist, an error is returned. Replacing * with Actual Field Names: The preprocessor replaces the * symbol (which denotes selecting all fields) with the actual field names of the table. This step is necessary to determine the specific fields to be retrieved from the table. Unlike the parser, the preprocessor step involves more than just local logic. During the preprocessing phase, it requires reading table information and potentially making API calls to check the existence of tables and fields. If we execute the following SQL statement and encounter an error, it is actually returned by the preprocessor: mysql\u003e select * from frined where id=1; ERROR 1146 (42S02): Table 'mysql_learn.frined' doesn't exist mysql\u003e In this example, the preprocessor identifies that the table name frined doesn’t exist, leading to an error indicating the table doesn’t exist in the specified database. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:4","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Optimizer After the SQL statement goes through the parser and preprocessor, it reaches the optimizer. Strictly speaking, at this point, it can no longer be called an SQL statement because it has been significantly transformed. The optimizer’s role is crucial because it selects an optimal execution plan based on the SQL statement and the actual data in the tables. For example, if a query has multiple indexes, the optimizer analyzes and determines which index to use based on the estimated cost. Additionally, if the table has a small amount of data, a full table scan might be more efficient than using an index. To understand the execution plan of a query, we often use the EXPLAIN command. By adding the EXPLAIN keyword before the SELECT statement, we can see the execution plan. Query 1: mysql\u003e explain select * from `like` where id=1; +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | 1 | SIMPLE | like | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL | +----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.04 sec) mysql\u003e Query 2: mysql\u003e explain select * from `like` limit 1; +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ | 1 | SIMPLE | like | NULL | index | NULL | uk_user_id_liker_id | 8 | NULL | 3 | 100.00 | Using index | +----+-------------+-------+------------+-------+---------------+---------------------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.03 sec) mysql\u003e In the above examples, the key column is not empty. In Query 1, MySQL chooses to use the PRIMARY key index, while in Query 2, it uses the uk_user_id_liker_id unique index. If the key column is empty, it means that no index is used, and a full table scan is performed. In practice, even for identical SQL statements, the execution plan may vary depending on various factors, including indexes and the size of table data. In summary, MySQL’s optimizer selects a relatively optimal execution plan based on several conditions to minimize the execution cost of SQL statements. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:5","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Executor After the preceding steps, we finally come to the actual execution of the SQL statement. The executor acts as a bridge between the MySQL server layer and the storage engine layer. The executor doesn’t execute the SQL statement directly; instead, it passes the processed “SQL statement” to the storage engine through API interfaces. It then waits for the storage engine to return the execution results, which are then passed back to the query cache and the connector. ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:1:6","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Indexes ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:2:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Three Main Logs ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:3:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Undo Log ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:3:1","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Redo Log ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:3:2","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Binary Log ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:3:3","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Locks ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:4:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Transactions ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:5:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Atomicity ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:5:1","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Durability ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:5:2","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Isolation ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:5:3","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Consistency ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:5:4","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Data Structures ","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:6:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Memory","date":"2023-07-01","objectID":"https://www.bardblog.cn/en/mysql-core-concepts/:7:0","tags":["MySQL","InnoDB"],"title":"Core Concepts of MySQL","uri":"https://www.bardblog.cn/en/mysql-core-concepts/"},{"categories":["technology"],"content":"Introduction to some less common advanced usage of Git","date":"2023-06-27","objectID":"https://www.bardblog.cn/en/git-advanced-usage/","tags":["git","linux"],"title":"Advanced Usage of Git","uri":"https://www.bardblog.cn/en/git-advanced-usage/"},{"categories":["technology"],"content":"Git Submodules ","date":"2023-06-27","objectID":"https://www.bardblog.cn/en/git-advanced-usage/:1:0","tags":["git","linux"],"title":"Advanced Usage of Git","uri":"https://www.bardblog.cn/en/git-advanced-usage/"},{"categories":["technology"],"content":"Concept Git submodules allow you to include another Git repository as a subdirectory within your main (parent) repository. Each submodule is an independent Git project with its own commits, pull requests, and pushes. The parent repository includes multiple submodules as part of its structure. ","date":"2023-06-27","objectID":"https://www.bardblog.cn/en/git-advanced-usage/:1:1","tags":["git","linux"],"title":"Advanced Usage of Git","uri":"https://www.bardblog.cn/en/git-advanced-usage/"},{"categories":["technology"],"content":"Example Let’s walk through an example to understand how to use Git submodules. Create a folder named “gitSubmodules” and initialize it as a Git repository: mkdir gitSubmodules cd gitSubmodules git init Add a remote origin and push the repository to GitHub: git remote add origin git@github.com:YOUR_USERNAME/gitSubmodules.git echo \"About gitSubmodules\" \u003e\u003e README.md git add . git commit -m \"Initialize gitSubmodules\" git push --set-upstream origin main Here, replace “YOUR_USERNAME” with your actual GitHub username. Now, let’s add two submodules to the “gitSubmodules” repository: git submodule add git@github.com:YOUR_USERNAME/submodule1.git git submodule add git@github.com:YOUR_USERNAME/submodule2.git By executing these commands, the submodules “submodule1” and “submodule2” will be added to the “gitSubmodules” repository. This command will clone the remote repositories of the submodules into the root directory of the “gitSubmodules” repository. By default, each submodule will be placed in a directory with the same name as the submodule repository. If you run git status at this point, you will see that the repository now contains a new file named “.gitmodules” and two new directories: “submodule1” and “submodule2”. The “.gitmodules” file stores the mapping between the local directory paths and the remote repository URLs of the submodules. Commit and push the changes to the parent repository: git add . git commit -m \"Add submodule1 and submodule2 submodules\" git push This will push the submodule information to the remote repository as well. If someone else clones the “gitSubmodules” repository, they will initially have empty directories for the submodules. To populate the submodules with their respective contents, they need to run the following commands: git submodule init git submodule update After running these commands, the submodules’ remote files will be synchronized to the local repository, including the commit information for each submodule. ","date":"2023-06-27","objectID":"https://www.bardblog.cn/en/git-advanced-usage/:1:2","tags":["git","linux"],"title":"Advanced Usage of Git","uri":"https://www.bardblog.cn/en/git-advanced-usage/"},{"categories":["technology"],"content":"Use Cases Git submodules are useful when you need to include other projects within your main project. Each project can have its own separate repository and version control history, ensuring that modifications to the main and submodules do not affect each other. ","date":"2023-06-27","objectID":"https://www.bardblog.cn/en/git-advanced-usage/:1:3","tags":["git","linux"],"title":"Advanced Usage of Git","uri":"https://www.bardblog.cn/en/git-advanced-usage/"},{"categories":null,"content":"About Bard","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/about/","tags":null,"title":"About Bard","uri":"https://www.bardblog.cn/en/about/"},{"categories":null,"content":"English name: BardChen Location: ShenZhen Carrer: Programmer Sports：Running, badminton, mountain climbing. Blog soucre code：https://github.com/YourFantasy/blog Blog Philosophy：Record life and growth. ","date":"2023-06-24","objectID":"https://www.bardblog.cn/en/about/:0:0","tags":null,"title":"About Bard","uri":"https://www.bardblog.cn/en/about/"}]